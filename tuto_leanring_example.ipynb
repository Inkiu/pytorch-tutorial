{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warm-up numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1000) (64, 10)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100) (100, 10)\n"
     ]
    }
   ],
   "source": [
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "print(w1.shape, w2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100) (64, 10)\n",
      "0 9.580017659581427e-06\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-6\n",
    "for t in range(1):\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "    \n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(t, loss)\n",
    "    \n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred) # ??? dot????\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "    \n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 26543278.0\n",
      "1 26972794.0\n",
      "2 29946700.0\n",
      "3 30923972.0\n",
      "4 27085276.0\n",
      "5 18868808.0\n",
      "6 10908052.0\n",
      "7 5613822.5\n",
      "8 2954080.0\n",
      "9 1720409.5\n",
      "10 1147969.5\n",
      "11 854924.5\n",
      "12 683733.875\n",
      "13 569418.9375\n",
      "14 484984.90625\n",
      "15 418463.1875\n",
      "16 364080.40625\n",
      "17 318642.0625\n",
      "18 280259.40625\n",
      "19 247503.25\n",
      "20 219354.78125\n",
      "21 195068.71875\n",
      "22 174000.046875\n",
      "23 155629.125\n",
      "24 139550.0625\n",
      "25 125419.734375\n",
      "26 112968.7734375\n",
      "27 101969.140625\n",
      "28 92226.9375\n",
      "29 83601.53125\n",
      "30 75962.40625\n",
      "31 69154.03125\n",
      "32 63056.6328125\n",
      "33 57586.859375\n",
      "34 52666.40625\n",
      "35 48233.5859375\n",
      "36 44235.6875\n",
      "37 40620.9453125\n",
      "38 37345.81640625\n",
      "39 34372.65625\n",
      "40 31670.2734375\n",
      "41 29209.53125\n",
      "42 26966.623046875\n",
      "43 24920.236328125\n",
      "44 23050.330078125\n",
      "45 21338.6953125\n",
      "46 19770.642578125\n",
      "47 18333.359375\n",
      "48 17014.595703125\n",
      "49 15802.0087890625\n",
      "50 14685.775390625\n",
      "51 13657.697265625\n",
      "52 12710.056640625\n",
      "53 11835.591796875\n",
      "54 11027.830078125\n",
      "55 10282.19921875\n",
      "56 9593.041015625\n",
      "57 8954.6611328125\n",
      "58 8363.23046875\n",
      "59 7814.8359375\n",
      "60 7306.005859375\n",
      "61 6834.630859375\n",
      "62 6397.2880859375\n",
      "63 5991.1943359375\n",
      "64 5613.33251953125\n",
      "65 5261.552734375\n",
      "66 4933.626953125\n",
      "67 4628.048828125\n",
      "68 4343.1376953125\n",
      "69 4077.115478515625\n",
      "70 3828.79296875\n",
      "71 3596.82373046875\n",
      "72 3380.14892578125\n",
      "73 3177.58935546875\n",
      "74 2988.09619140625\n",
      "75 2810.738525390625\n",
      "76 2644.701171875\n",
      "77 2489.1513671875\n",
      "78 2343.5498046875\n",
      "79 2207.138427734375\n",
      "80 2079.308349609375\n",
      "81 1959.4022216796875\n",
      "82 1846.8643798828125\n",
      "83 1742.1763916015625\n",
      "84 1643.877685546875\n",
      "85 1551.558837890625\n",
      "86 1464.81591796875\n",
      "87 1383.278564453125\n",
      "88 1306.6473388671875\n",
      "89 1234.51708984375\n",
      "90 1166.62744140625\n",
      "91 1102.7235107421875\n",
      "92 1042.54052734375\n",
      "93 985.889892578125\n",
      "94 932.492431640625\n",
      "95 882.1852416992188\n",
      "96 834.7452392578125\n",
      "97 790.0161743164062\n",
      "98 747.8060302734375\n",
      "99 707.971923828125\n",
      "100 670.4219360351562\n",
      "101 635.01806640625\n",
      "102 601.5498046875\n",
      "103 569.9375610351562\n",
      "104 540.087158203125\n",
      "105 511.88604736328125\n",
      "106 485.23858642578125\n",
      "107 460.0589599609375\n",
      "108 436.2438659667969\n",
      "109 413.73876953125\n",
      "110 392.435302734375\n",
      "111 372.28472900390625\n",
      "112 353.22003173828125\n",
      "113 335.19024658203125\n",
      "114 318.118896484375\n",
      "115 301.95703125\n",
      "116 286.653564453125\n",
      "117 272.162109375\n",
      "118 258.4388122558594\n",
      "119 245.4534149169922\n",
      "120 233.13645935058594\n",
      "121 221.46453857421875\n",
      "122 210.4056396484375\n",
      "123 199.9180145263672\n",
      "124 189.9773406982422\n",
      "125 180.55755615234375\n",
      "126 171.62225341796875\n",
      "127 163.1435546875\n",
      "128 155.09817504882812\n",
      "129 147.4669189453125\n",
      "130 140.2294921875\n",
      "131 133.36093139648438\n",
      "132 126.83828735351562\n",
      "133 120.651123046875\n",
      "134 114.7734146118164\n",
      "135 109.19229125976562\n",
      "136 103.90618896484375\n",
      "137 98.87771606445312\n",
      "138 94.10428619384766\n",
      "139 89.56794738769531\n",
      "140 85.25676727294922\n",
      "141 81.16482543945312\n",
      "142 77.27511596679688\n",
      "143 73.576416015625\n",
      "144 70.06044006347656\n",
      "145 66.7183837890625\n",
      "146 63.54114532470703\n",
      "147 60.52357482910156\n",
      "148 57.65077209472656\n",
      "149 54.92035675048828\n",
      "150 52.322509765625\n",
      "151 49.85260772705078\n",
      "152 47.50391387939453\n",
      "153 45.26603317260742\n",
      "154 43.13739013671875\n",
      "155 41.11088943481445\n",
      "156 39.18280792236328\n",
      "157 37.35002136230469\n",
      "158 35.603302001953125\n",
      "159 33.94054412841797\n",
      "160 32.35727310180664\n",
      "161 30.850547790527344\n",
      "162 29.416738510131836\n",
      "163 28.05044937133789\n",
      "164 26.749370574951172\n",
      "165 25.51022720336914\n",
      "166 24.329532623291016\n",
      "167 23.206199645996094\n",
      "168 22.13504981994629\n",
      "169 21.1141414642334\n",
      "170 20.142005920410156\n",
      "171 19.21551513671875\n",
      "172 18.333534240722656\n",
      "173 17.49150848388672\n",
      "174 16.689579010009766\n",
      "175 15.925506591796875\n",
      "176 15.197179794311523\n",
      "177 14.503368377685547\n",
      "178 13.841316223144531\n",
      "179 13.210295677185059\n",
      "180 12.608987808227539\n",
      "181 12.035706520080566\n",
      "182 11.489316940307617\n",
      "183 10.96716594696045\n",
      "184 10.469779968261719\n",
      "185 9.99538516998291\n",
      "186 9.543071746826172\n",
      "187 9.111927032470703\n",
      "188 8.700191497802734\n",
      "189 8.306999206542969\n",
      "190 7.93234920501709\n",
      "191 7.575166702270508\n",
      "192 7.2341156005859375\n",
      "193 6.908827781677246\n",
      "194 6.59830904006958\n",
      "195 6.301919937133789\n",
      "196 6.019537925720215\n",
      "197 5.749729156494141\n",
      "198 5.49214506149292\n",
      "199 5.246481895446777\n",
      "200 5.011735439300537\n",
      "201 4.788244724273682\n",
      "202 4.57460880279541\n",
      "203 4.370661735534668\n",
      "204 4.175683975219727\n",
      "205 3.9897966384887695\n",
      "206 3.812378168106079\n",
      "207 3.6428422927856445\n",
      "208 3.481074810028076\n",
      "209 3.3263816833496094\n",
      "210 3.178846836090088\n",
      "211 3.038112163543701\n",
      "212 2.9035325050354004\n",
      "213 2.7750353813171387\n",
      "214 2.6524336338043213\n",
      "215 2.5351927280426025\n",
      "216 2.4233169555664062\n",
      "217 2.3162975311279297\n",
      "218 2.2142417430877686\n",
      "219 2.116621494293213\n",
      "220 2.023404598236084\n",
      "221 1.934443712234497\n",
      "222 1.8490707874298096\n",
      "223 1.7680195569992065\n",
      "224 1.6902893781661987\n",
      "225 1.6161067485809326\n",
      "226 1.5452669858932495\n",
      "227 1.4775502681732178\n",
      "228 1.412775993347168\n",
      "229 1.350939393043518\n",
      "230 1.2918614149093628\n",
      "231 1.2352330684661865\n",
      "232 1.1812620162963867\n",
      "233 1.1296637058258057\n",
      "234 1.0804144144058228\n",
      "235 1.0332238674163818\n",
      "236 0.9882147908210754\n",
      "237 0.9451234936714172\n",
      "238 0.9039666652679443\n",
      "239 0.8645826578140259\n",
      "240 0.8269412517547607\n",
      "241 0.790981650352478\n",
      "242 0.7566332221031189\n",
      "243 0.723831057548523\n",
      "244 0.6924257874488831\n",
      "245 0.6624102592468262\n",
      "246 0.633629322052002\n",
      "247 0.6061729192733765\n",
      "248 0.5799769163131714\n",
      "249 0.5548784732818604\n",
      "250 0.5308828353881836\n",
      "251 0.507926344871521\n",
      "252 0.4859898090362549\n",
      "253 0.4649595320224762\n",
      "254 0.4448748230934143\n",
      "255 0.4256924092769623\n",
      "256 0.4073861241340637\n",
      "257 0.3897865414619446\n",
      "258 0.3729534149169922\n",
      "259 0.35700923204421997\n",
      "260 0.3415805995464325\n",
      "261 0.3268664479255676\n",
      "262 0.3128105401992798\n",
      "263 0.29936784505844116\n",
      "264 0.2865552306175232\n",
      "265 0.27421432733535767\n",
      "266 0.26247265934944153\n",
      "267 0.2512151896953583\n",
      "268 0.2404196560382843\n",
      "269 0.23011355102062225\n",
      "270 0.2202983796596527\n",
      "271 0.21084654331207275\n",
      "272 0.201781764626503\n",
      "273 0.19317179918289185\n",
      "274 0.18493260443210602\n",
      "275 0.1770150065422058\n",
      "276 0.16944342851638794\n",
      "277 0.16220977902412415\n",
      "278 0.15532121062278748\n",
      "279 0.14870011806488037\n",
      "280 0.14235557615756989\n",
      "281 0.1362932324409485\n",
      "282 0.13047057390213013\n",
      "283 0.12489043921232224\n",
      "284 0.11958177387714386\n",
      "285 0.11451202630996704\n",
      "286 0.10962539911270142\n",
      "287 0.10496341437101364\n",
      "288 0.10049386322498322\n",
      "289 0.09624668955802917\n",
      "290 0.09215478599071503\n",
      "291 0.08826187252998352\n",
      "292 0.08450280129909515\n",
      "293 0.08093766123056412\n",
      "294 0.07750113308429718\n",
      "295 0.07423120737075806\n",
      "296 0.07107962667942047\n",
      "297 0.068068727850914\n",
      "298 0.06517864763736725\n",
      "299 0.062434546649456024\n",
      "300 0.05980070307850838\n",
      "301 0.05729009583592415\n",
      "302 0.05486731231212616\n",
      "303 0.05255885422229767\n",
      "304 0.050334323197603226\n",
      "305 0.04821204021573067\n",
      "306 0.046190232038497925\n",
      "307 0.04424576833844185\n",
      "308 0.04238457977771759\n",
      "309 0.04060954600572586\n",
      "310 0.03890122473239899\n",
      "311 0.03727281466126442\n",
      "312 0.035704270005226135\n",
      "313 0.03421600162982941\n",
      "314 0.03277779743075371\n",
      "315 0.03139539435505867\n",
      "316 0.030096370726823807\n",
      "317 0.02883864939212799\n",
      "318 0.027633916586637497\n",
      "319 0.026481028646230698\n",
      "320 0.02536749839782715\n",
      "321 0.024322010576725006\n",
      "322 0.02331509441137314\n",
      "323 0.022332938387989998\n",
      "324 0.021409647539258003\n",
      "325 0.020521633327007294\n",
      "326 0.01966642588376999\n",
      "327 0.01884884387254715\n",
      "328 0.018068920820951462\n",
      "329 0.01733117550611496\n",
      "330 0.016619045287370682\n",
      "331 0.01593431830406189\n",
      "332 0.015286387875676155\n",
      "333 0.01465640403330326\n",
      "334 0.014056789688766003\n",
      "335 0.013477103784680367\n",
      "336 0.012934209778904915\n",
      "337 0.012401322834193707\n",
      "338 0.011897971853613853\n",
      "339 0.011413894593715668\n",
      "340 0.010954426601529121\n",
      "341 0.010511286556720734\n",
      "342 0.010091204196214676\n",
      "343 0.00968678668141365\n",
      "344 0.009296828880906105\n",
      "345 0.00892059225589037\n",
      "346 0.008561118505895138\n",
      "347 0.008215687237679958\n",
      "348 0.007886813022196293\n",
      "349 0.007571955677121878\n",
      "350 0.007270500063896179\n",
      "351 0.0069831786677241325\n",
      "352 0.006705034524202347\n",
      "353 0.006440678145736456\n",
      "354 0.006185659673064947\n",
      "355 0.005943397060036659\n",
      "356 0.005712458863854408\n",
      "357 0.005491461139172316\n",
      "358 0.005277312360703945\n",
      "359 0.005070533603429794\n",
      "360 0.004872377496212721\n",
      "361 0.004685429390519857\n",
      "362 0.0045042079873383045\n",
      "363 0.004332463722676039\n",
      "364 0.004166345112025738\n",
      "365 0.0040075224824249744\n",
      "366 0.0038577555678784847\n",
      "367 0.0037119011394679546\n",
      "368 0.0035741098690778017\n",
      "369 0.0034386790357530117\n",
      "370 0.0033082012087106705\n",
      "371 0.0031854708213359118\n",
      "372 0.003067383076995611\n",
      "373 0.0029511083848774433\n",
      "374 0.0028449036180973053\n",
      "375 0.0027391002513468266\n",
      "376 0.0026437328197062016\n",
      "377 0.0025474620051681995\n",
      "378 0.0024570911191403866\n",
      "379 0.0023680638987571\n",
      "380 0.0022829098161309958\n",
      "381 0.0022027199156582355\n",
      "382 0.0021252441219985485\n",
      "383 0.0020504631102085114\n",
      "384 0.001978508196771145\n",
      "385 0.0019100209465250373\n",
      "386 0.0018440934363752604\n",
      "387 0.0017798239132389426\n",
      "388 0.0017211886588484049\n",
      "389 0.001660084817558527\n",
      "390 0.001603951444849372\n",
      "391 0.001551617169752717\n",
      "392 0.0014992877840995789\n",
      "393 0.0014506230363622308\n",
      "394 0.0014023501425981522\n",
      "395 0.0013562035746872425\n",
      "396 0.001311497064307332\n",
      "397 0.0012685867259278893\n",
      "398 0.0012260336661711335\n",
      "399 0.0011876554926857352\n",
      "400 0.001149945193901658\n",
      "401 0.0011135017266497016\n",
      "402 0.0010786586208269\n",
      "403 0.001043207012116909\n",
      "404 0.0010121205123141408\n",
      "405 0.0009804916335269809\n",
      "406 0.0009491513483226299\n",
      "407 0.0009201854118146002\n",
      "408 0.0008918478852137923\n",
      "409 0.000864977715536952\n",
      "410 0.000838891020976007\n",
      "411 0.0008136385004036129\n",
      "412 0.0007890030974522233\n",
      "413 0.000765422242693603\n",
      "414 0.0007432092679664493\n",
      "415 0.0007216774392873049\n",
      "416 0.0006997904274612665\n",
      "417 0.0006793910870328546\n",
      "418 0.0006597897736355662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419 0.0006420455756597221\n",
      "420 0.0006243606912903488\n",
      "421 0.0006069435039535165\n",
      "422 0.000589379109442234\n",
      "423 0.0005731815472245216\n",
      "424 0.0005583447054959834\n",
      "425 0.0005428734584711492\n",
      "426 0.0005282448837533593\n",
      "427 0.0005136646796017885\n",
      "428 0.0004996279603801668\n",
      "429 0.00048637879081070423\n",
      "430 0.000473411608254537\n",
      "431 0.000461524206912145\n",
      "432 0.00044908415293321013\n",
      "433 0.00043799920240417123\n",
      "434 0.00042595143895596266\n",
      "435 0.0004153897170908749\n",
      "436 0.00040440872544422746\n",
      "437 0.0003940195310860872\n",
      "438 0.0003836000105366111\n",
      "439 0.0003750735195353627\n",
      "440 0.00036519853165373206\n",
      "441 0.00035614840453490615\n",
      "442 0.0003473130927886814\n",
      "443 0.00033915776293724775\n",
      "444 0.0003313008928671479\n",
      "445 0.00032311808899976313\n",
      "446 0.000314869248541072\n",
      "447 0.00030760420486330986\n",
      "448 0.0003009967622347176\n",
      "449 0.0002936685341410339\n",
      "450 0.00028637039940804243\n",
      "451 0.0002798016939777881\n",
      "452 0.0002737695467658341\n",
      "453 0.00026765474467538297\n",
      "454 0.0002616900601424277\n",
      "455 0.0002553851518314332\n",
      "456 0.0002491922350600362\n",
      "457 0.00024355339701287448\n",
      "458 0.00023780445917509496\n",
      "459 0.0002330220304429531\n",
      "460 0.00022780754079576582\n",
      "461 0.00022313464432954788\n",
      "462 0.00021870352793484926\n",
      "463 0.00021357866353355348\n",
      "464 0.00020870863227173686\n",
      "465 0.00020446424605324864\n",
      "466 0.00020030021551065147\n",
      "467 0.00019563734531402588\n",
      "468 0.00019191973842680454\n",
      "469 0.00018782250117510557\n",
      "470 0.00018463032029103488\n",
      "471 0.00018091365927830338\n",
      "472 0.0001771368843037635\n",
      "473 0.00017384157399646938\n",
      "474 0.00017050806491170079\n",
      "475 0.0001669621269684285\n",
      "476 0.0001637497334741056\n",
      "477 0.00016043309005908668\n",
      "478 0.00015744398115202785\n",
      "479 0.00015391333727166057\n",
      "480 0.00015145272482186556\n",
      "481 0.0001484559033997357\n",
      "482 0.00014588446356356144\n",
      "483 0.0001429223921149969\n",
      "484 0.00014024568372406065\n",
      "485 0.0001376180734951049\n",
      "486 0.0001351019600406289\n",
      "487 0.00013256673992145807\n",
      "488 0.00012995500583201647\n",
      "489 0.00012800800323020667\n",
      "490 0.00012530176900327206\n",
      "491 0.00012302845425438136\n",
      "492 0.00012073550169588998\n",
      "493 0.00011923070269403979\n",
      "494 0.00011663019540719688\n",
      "495 0.00011459140660008416\n",
      "496 0.00011262398038525134\n",
      "497 0.0001105569681385532\n",
      "498 0.00010886352538364008\n",
      "499 0.00010729592759162188\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    h = x.mm(w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "    \n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    print(t, loss)\n",
    "    \n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(31688700., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "1 tensor(27520140., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "2 tensor(26636608., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "3 tensor(25122548., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "4 tensor(21159136., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "5 tensor(15523048., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "6 tensor(10010263., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "7 tensor(6002935., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "8 tensor(3551256.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "9 tensor(2194559., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "10 tensor(1458335., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "11 tensor(1048400.3750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "12 tensor(804717.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "13 tensor(647582.0625, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "14 tensor(537831.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "15 tensor(455932.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "16 tensor(391808.0312, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "17 tensor(339779.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "18 tensor(296635.3750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "19 tensor(260321.7656, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "20 tensor(229487.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "21 tensor(203071.0781, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "22 tensor(180270.4688, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "23 tensor(160501.9688, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "24 tensor(143277.2969, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "25 tensor(128221.5469, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "26 tensor(115008.8672, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "27 tensor(103363.8203, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "28 tensor(93069.4375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "29 tensor(83949.1484, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "30 tensor(75845.6250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "31 tensor(68627.2188, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "32 tensor(62188.8516, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "33 tensor(56427.1016, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "34 tensor(51264.6953, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "35 tensor(46630.6484, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "36 tensor(42464.7344, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "37 tensor(38714.7969, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "38 tensor(35336.7148, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "39 tensor(32287.3789, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "40 tensor(29529.7930, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "41 tensor(27030.8164, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "42 tensor(24764.8184, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "43 tensor(22706.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "44 tensor(20836.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "45 tensor(19135.7305, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "46 tensor(17585.2969, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "47 tensor(16171.7422, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "48 tensor(14882.0488, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "49 tensor(13704.1162, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "50 tensor(12627.3301, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "51 tensor(11642.0488, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "52 tensor(10740.0781, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "53 tensor(9913.7617, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "54 tensor(9156.0547, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "55 tensor(8460.8135, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "56 tensor(7822.6201, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "57 tensor(7236.2026, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "58 tensor(6696.9971, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "59 tensor(6201.2065, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "60 tensor(5745.0811, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "61 tensor(5324.9204, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "62 tensor(4937.6074, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "63 tensor(4580.5972, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "64 tensor(4251.3213, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "65 tensor(3947.5652, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "66 tensor(3667.2410, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "67 tensor(3408.1851, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "68 tensor(3168.7412, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "69 tensor(2947.3516, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "70 tensor(2742.4771, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "71 tensor(2552.9377, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "72 tensor(2377.4128, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "73 tensor(2214.8442, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "74 tensor(2064.1416, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "75 tensor(1924.3695, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "76 tensor(1794.7490, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "77 tensor(1674.6045, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "78 tensor(1562.9979, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "79 tensor(1459.3071, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "80 tensor(1362.9495, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "81 tensor(1273.4023, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "82 tensor(1190.0735, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "83 tensor(1112.5762, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "84 tensor(1040.4187, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "85 tensor(973.2452, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "86 tensor(910.6690, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "87 tensor(852.3826, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "88 tensor(798.0663, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "89 tensor(747.4475, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "90 tensor(700.2222, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "91 tensor(656.1447, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "92 tensor(615.0255, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "93 tensor(576.6360, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "94 tensor(540.7745, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "95 tensor(507.2792, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "96 tensor(475.9944, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "97 tensor(446.7355, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "98 tensor(419.3826, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "99 tensor(393.7966, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "100 tensor(369.8605, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "101 tensor(347.4701, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "102 tensor(326.5269, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "103 tensor(306.9409, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "104 tensor(288.6048, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "105 tensor(271.4174, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "106 tensor(255.3135, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "107 tensor(240.2188, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "108 tensor(226.0629, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "109 tensor(212.7966, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "110 tensor(200.3487, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "111 tensor(188.6609, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "112 tensor(177.6905, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "113 tensor(167.3909, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "114 tensor(157.7212, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "115 tensor(148.6383, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "116 tensor(140.1037, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "117 tensor(132.0826, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "118 tensor(124.5407, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "119 tensor(117.4512, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "120 tensor(110.7860, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "121 tensor(104.5184, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "122 tensor(98.6293, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "123 tensor(93.0869, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "124 tensor(87.8697, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "125 tensor(82.9567, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "126 tensor(78.3325, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "127 tensor(73.9765, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "128 tensor(69.8722, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "129 tensor(66.0060, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "130 tensor(62.3624, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "131 tensor(58.9279, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "132 tensor(55.6914, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "133 tensor(52.6391, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "134 tensor(49.7589, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "135 tensor(47.0446, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "136 tensor(44.4838, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "137 tensor(42.0673, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "138 tensor(39.7871, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "139 tensor(37.6356, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "140 tensor(35.6045, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "141 tensor(33.6862, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "142 tensor(31.8754, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "143 tensor(30.1651, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "144 tensor(28.5501, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "145 tensor(27.0244, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "146 tensor(25.5829, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "147 tensor(24.2209, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "148 tensor(22.9343, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "149 tensor(21.7179, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "150 tensor(20.5676, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "151 tensor(19.4814, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "152 tensor(18.4531, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "153 tensor(17.4808, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "154 tensor(16.5621, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "155 tensor(15.6926, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "156 tensor(14.8699, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "157 tensor(14.0919, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "158 tensor(13.3554, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "159 tensor(12.6589, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "160 tensor(11.9996, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "161 tensor(11.3757, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "162 tensor(10.7856, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "163 tensor(10.2262, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "164 tensor(9.6965, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "165 tensor(9.1954, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "166 tensor(8.7205, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "167 tensor(8.2709, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "168 tensor(7.8451, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "169 tensor(7.4418, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "170 tensor(7.0594, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "171 tensor(6.6975, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172 tensor(6.3546, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "173 tensor(6.0295, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "174 tensor(5.7215, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "175 tensor(5.4296, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "176 tensor(5.1529, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "177 tensor(4.8907, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "178 tensor(4.6419, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "179 tensor(4.4061, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "180 tensor(4.1829, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "181 tensor(3.9708, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "182 tensor(3.7699, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "183 tensor(3.5793, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "184 tensor(3.3987, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "185 tensor(3.2272, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "186 tensor(3.0644, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "187 tensor(2.9101, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "188 tensor(2.7639, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "189 tensor(2.6250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "190 tensor(2.4933, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "191 tensor(2.3681, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "192 tensor(2.2497, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "193 tensor(2.1370, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "194 tensor(2.0301, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "195 tensor(1.9287, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "196 tensor(1.8326, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "197 tensor(1.7411, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "198 tensor(1.6543, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "199 tensor(1.5720, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "200 tensor(1.4938, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "201 tensor(1.4195, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "202 tensor(1.3490, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "203 tensor(1.2821, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "204 tensor(1.2185, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "205 tensor(1.1581, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "206 tensor(1.1008, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "207 tensor(1.0464, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "208 tensor(0.9946, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "209 tensor(0.9455, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "210 tensor(0.8988, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "211 tensor(0.8545, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "212 tensor(0.8123, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "213 tensor(0.7724, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "214 tensor(0.7344, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "215 tensor(0.6982, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "216 tensor(0.6640, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "217 tensor(0.6314, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "218 tensor(0.6003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "219 tensor(0.5708, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "220 tensor(0.5429, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "221 tensor(0.5163, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "222 tensor(0.4911, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "223 tensor(0.4670, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "224 tensor(0.4442, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "225 tensor(0.4224, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "226 tensor(0.4019, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "227 tensor(0.3822, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "228 tensor(0.3635, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "229 tensor(0.3459, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "230 tensor(0.3290, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "231 tensor(0.3130, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "232 tensor(0.2977, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "233 tensor(0.2832, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "234 tensor(0.2695, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "235 tensor(0.2564, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "236 tensor(0.2439, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "237 tensor(0.2321, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "238 tensor(0.2209, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "239 tensor(0.2101, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "240 tensor(0.2000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "241 tensor(0.1903, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "242 tensor(0.1811, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "243 tensor(0.1723, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "244 tensor(0.1639, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "245 tensor(0.1560, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "246 tensor(0.1485, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "247 tensor(0.1413, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "248 tensor(0.1345, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "249 tensor(0.1280, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "250 tensor(0.1218, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "251 tensor(0.1159, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "252 tensor(0.1104, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "253 tensor(0.1050, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "254 tensor(0.1000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "255 tensor(0.0952, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "256 tensor(0.0906, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "257 tensor(0.0863, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "258 tensor(0.0821, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "259 tensor(0.0781, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "260 tensor(0.0744, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "261 tensor(0.0708, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "262 tensor(0.0674, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "263 tensor(0.0642, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "264 tensor(0.0611, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "265 tensor(0.0582, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "266 tensor(0.0554, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "267 tensor(0.0528, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "268 tensor(0.0502, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "269 tensor(0.0478, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "270 tensor(0.0455, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "271 tensor(0.0434, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "272 tensor(0.0413, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "273 tensor(0.0393, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "274 tensor(0.0375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "275 tensor(0.0357, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "276 tensor(0.0340, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "277 tensor(0.0324, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "278 tensor(0.0308, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "279 tensor(0.0294, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "280 tensor(0.0280, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "281 tensor(0.0266, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "282 tensor(0.0254, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "283 tensor(0.0242, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "284 tensor(0.0230, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "285 tensor(0.0219, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "286 tensor(0.0209, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "287 tensor(0.0199, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "288 tensor(0.0190, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "289 tensor(0.0181, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "290 tensor(0.0172, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "291 tensor(0.0164, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "292 tensor(0.0156, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "293 tensor(0.0149, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "294 tensor(0.0142, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "295 tensor(0.0135, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "296 tensor(0.0129, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "297 tensor(0.0123, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "298 tensor(0.0117, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "299 tensor(0.0112, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "300 tensor(0.0107, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "301 tensor(0.0102, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "302 tensor(0.0097, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "303 tensor(0.0093, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "304 tensor(0.0088, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "305 tensor(0.0084, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "306 tensor(0.0080, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "307 tensor(0.0077, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "308 tensor(0.0073, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "309 tensor(0.0070, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "310 tensor(0.0067, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "311 tensor(0.0064, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "312 tensor(0.0061, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "313 tensor(0.0058, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "314 tensor(0.0056, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "315 tensor(0.0053, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "316 tensor(0.0051, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "317 tensor(0.0048, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "318 tensor(0.0046, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "319 tensor(0.0044, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "320 tensor(0.0042, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "321 tensor(0.0041, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "322 tensor(0.0039, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "323 tensor(0.0037, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "324 tensor(0.0035, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "325 tensor(0.0034, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "326 tensor(0.0032, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "327 tensor(0.0031, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "328 tensor(0.0030, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "329 tensor(0.0029, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "330 tensor(0.0027, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "331 tensor(0.0026, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "332 tensor(0.0025, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "333 tensor(0.0024, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "334 tensor(0.0023, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "335 tensor(0.0022, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "336 tensor(0.0021, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "337 tensor(0.0020, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "338 tensor(0.0020, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "339 tensor(0.0019, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "340 tensor(0.0018, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "341 tensor(0.0017, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "342 tensor(0.0017, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "343 tensor(0.0016, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "344 tensor(0.0015, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345 tensor(0.0015, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "346 tensor(0.0014, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "347 tensor(0.0014, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "348 tensor(0.0013, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "349 tensor(0.0013, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "350 tensor(0.0012, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "351 tensor(0.0012, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "352 tensor(0.0011, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "353 tensor(0.0011, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "354 tensor(0.0011, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "355 tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "356 tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "357 tensor(0.0009, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "358 tensor(0.0009, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "359 tensor(0.0009, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "360 tensor(0.0008, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "361 tensor(0.0008, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "362 tensor(0.0008, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "363 tensor(0.0008, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "364 tensor(0.0007, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "365 tensor(0.0007, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "366 tensor(0.0007, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "367 tensor(0.0007, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "368 tensor(0.0006, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "369 tensor(0.0006, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "370 tensor(0.0006, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "371 tensor(0.0006, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "372 tensor(0.0006, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "373 tensor(0.0006, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "374 tensor(0.0005, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "375 tensor(0.0005, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "376 tensor(0.0005, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "377 tensor(0.0005, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "378 tensor(0.0005, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "379 tensor(0.0005, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "380 tensor(0.0004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "381 tensor(0.0004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "382 tensor(0.0004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "383 tensor(0.0004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "384 tensor(0.0004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "385 tensor(0.0004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "386 tensor(0.0004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "387 tensor(0.0004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "388 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "389 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "390 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "391 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "392 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "393 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "394 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "395 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "396 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "397 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "398 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "399 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "400 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "401 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "402 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "403 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "404 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "405 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "406 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "407 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "408 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "409 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "410 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "411 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "412 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "413 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "414 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "415 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "416 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "417 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "418 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "419 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "420 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "421 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "422 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "423 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "424 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "425 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "426 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "427 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "428 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "429 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "430 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "431 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "432 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "433 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "434 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "435 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "436 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "437 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "438 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "439 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "440 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "441 tensor(9.9912e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "442 tensor(9.8018e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "443 tensor(9.6060e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "444 tensor(9.4212e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "445 tensor(9.2267e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "446 tensor(9.0772e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "447 tensor(8.9132e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "448 tensor(8.7734e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "449 tensor(8.6011e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "450 tensor(8.4408e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "451 tensor(8.2944e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "452 tensor(8.1415e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "453 tensor(8.0116e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "454 tensor(7.8577e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "455 tensor(7.7037e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "456 tensor(7.5659e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "457 tensor(7.4334e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "458 tensor(7.3205e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "459 tensor(7.1939e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "460 tensor(7.0510e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "461 tensor(6.9150e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "462 tensor(6.8123e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "463 tensor(6.7249e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "464 tensor(6.6046e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "465 tensor(6.4996e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "466 tensor(6.3766e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "467 tensor(6.2749e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "468 tensor(6.1717e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "469 tensor(6.0798e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "470 tensor(5.9998e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "471 tensor(5.8904e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "472 tensor(5.8116e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "473 tensor(5.7052e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "474 tensor(5.6169e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "475 tensor(5.5476e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "476 tensor(5.4803e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "477 tensor(5.3886e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "478 tensor(5.2912e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "479 tensor(5.2129e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "480 tensor(5.1236e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "481 tensor(5.0470e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "482 tensor(4.9929e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "483 tensor(4.9173e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "484 tensor(4.8265e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "485 tensor(4.7617e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "486 tensor(4.6969e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "487 tensor(4.6368e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "488 tensor(4.5776e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "489 tensor(4.5148e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "490 tensor(4.4443e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "491 tensor(4.3773e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "492 tensor(4.3225e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "493 tensor(4.2609e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "494 tensor(4.2141e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "495 tensor(4.1531e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "496 tensor(4.0997e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "497 tensor(4.0451e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "498 tensor(3.9836e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "499 tensor(3.9478e-05, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    \n",
    "    print(t, loss)\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "        \n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(645.1180, grad_fn=<MseLossBackward>)\n",
      "1 tensor(596.0870, grad_fn=<MseLossBackward>)\n",
      "2 tensor(554.5156, grad_fn=<MseLossBackward>)\n",
      "3 tensor(518.5646, grad_fn=<MseLossBackward>)\n",
      "4 tensor(487.2771, grad_fn=<MseLossBackward>)\n",
      "5 tensor(459.1722, grad_fn=<MseLossBackward>)\n",
      "6 tensor(433.6836, grad_fn=<MseLossBackward>)\n",
      "7 tensor(410.2769, grad_fn=<MseLossBackward>)\n",
      "8 tensor(388.6653, grad_fn=<MseLossBackward>)\n",
      "9 tensor(368.8993, grad_fn=<MseLossBackward>)\n",
      "10 tensor(350.5129, grad_fn=<MseLossBackward>)\n",
      "11 tensor(333.1784, grad_fn=<MseLossBackward>)\n",
      "12 tensor(316.8432, grad_fn=<MseLossBackward>)\n",
      "13 tensor(301.3418, grad_fn=<MseLossBackward>)\n",
      "14 tensor(286.6488, grad_fn=<MseLossBackward>)\n",
      "15 tensor(272.6128, grad_fn=<MseLossBackward>)\n",
      "16 tensor(259.1991, grad_fn=<MseLossBackward>)\n",
      "17 tensor(246.4363, grad_fn=<MseLossBackward>)\n",
      "18 tensor(234.2988, grad_fn=<MseLossBackward>)\n",
      "19 tensor(222.7094, grad_fn=<MseLossBackward>)\n",
      "20 tensor(211.6112, grad_fn=<MseLossBackward>)\n",
      "21 tensor(201.0506, grad_fn=<MseLossBackward>)\n",
      "22 tensor(190.9601, grad_fn=<MseLossBackward>)\n",
      "23 tensor(181.2943, grad_fn=<MseLossBackward>)\n",
      "24 tensor(172.0373, grad_fn=<MseLossBackward>)\n",
      "25 tensor(163.2066, grad_fn=<MseLossBackward>)\n",
      "26 tensor(154.7738, grad_fn=<MseLossBackward>)\n",
      "27 tensor(146.7495, grad_fn=<MseLossBackward>)\n",
      "28 tensor(139.1148, grad_fn=<MseLossBackward>)\n",
      "29 tensor(131.8451, grad_fn=<MseLossBackward>)\n",
      "30 tensor(124.9183, grad_fn=<MseLossBackward>)\n",
      "31 tensor(118.3131, grad_fn=<MseLossBackward>)\n",
      "32 tensor(112.0193, grad_fn=<MseLossBackward>)\n",
      "33 tensor(106.0438, grad_fn=<MseLossBackward>)\n",
      "34 tensor(100.3664, grad_fn=<MseLossBackward>)\n",
      "35 tensor(94.9794, grad_fn=<MseLossBackward>)\n",
      "36 tensor(89.8739, grad_fn=<MseLossBackward>)\n",
      "37 tensor(85.0355, grad_fn=<MseLossBackward>)\n",
      "38 tensor(80.4443, grad_fn=<MseLossBackward>)\n",
      "39 tensor(76.0858, grad_fn=<MseLossBackward>)\n",
      "40 tensor(71.9582, grad_fn=<MseLossBackward>)\n",
      "41 tensor(68.0421, grad_fn=<MseLossBackward>)\n",
      "42 tensor(64.3428, grad_fn=<MseLossBackward>)\n",
      "43 tensor(60.8420, grad_fn=<MseLossBackward>)\n",
      "44 tensor(57.5373, grad_fn=<MseLossBackward>)\n",
      "45 tensor(54.3947, grad_fn=<MseLossBackward>)\n",
      "46 tensor(51.4237, grad_fn=<MseLossBackward>)\n",
      "47 tensor(48.6221, grad_fn=<MseLossBackward>)\n",
      "48 tensor(45.9764, grad_fn=<MseLossBackward>)\n",
      "49 tensor(43.4803, grad_fn=<MseLossBackward>)\n",
      "50 tensor(41.1240, grad_fn=<MseLossBackward>)\n",
      "51 tensor(38.9038, grad_fn=<MseLossBackward>)\n",
      "52 tensor(36.8119, grad_fn=<MseLossBackward>)\n",
      "53 tensor(34.8361, grad_fn=<MseLossBackward>)\n",
      "54 tensor(32.9737, grad_fn=<MseLossBackward>)\n",
      "55 tensor(31.2205, grad_fn=<MseLossBackward>)\n",
      "56 tensor(29.5669, grad_fn=<MseLossBackward>)\n",
      "57 tensor(28.0075, grad_fn=<MseLossBackward>)\n",
      "58 tensor(26.5377, grad_fn=<MseLossBackward>)\n",
      "59 tensor(25.1502, grad_fn=<MseLossBackward>)\n",
      "60 tensor(23.8408, grad_fn=<MseLossBackward>)\n",
      "61 tensor(22.6072, grad_fn=<MseLossBackward>)\n",
      "62 tensor(21.4429, grad_fn=<MseLossBackward>)\n",
      "63 tensor(20.3425, grad_fn=<MseLossBackward>)\n",
      "64 tensor(19.3005, grad_fn=<MseLossBackward>)\n",
      "65 tensor(18.3186, grad_fn=<MseLossBackward>)\n",
      "66 tensor(17.3902, grad_fn=<MseLossBackward>)\n",
      "67 tensor(16.5122, grad_fn=<MseLossBackward>)\n",
      "68 tensor(15.6831, grad_fn=<MseLossBackward>)\n",
      "69 tensor(14.9002, grad_fn=<MseLossBackward>)\n",
      "70 tensor(14.1605, grad_fn=<MseLossBackward>)\n",
      "71 tensor(13.4595, grad_fn=<MseLossBackward>)\n",
      "72 tensor(12.7966, grad_fn=<MseLossBackward>)\n",
      "73 tensor(12.1691, grad_fn=<MseLossBackward>)\n",
      "74 tensor(11.5755, grad_fn=<MseLossBackward>)\n",
      "75 tensor(11.0151, grad_fn=<MseLossBackward>)\n",
      "76 tensor(10.4849, grad_fn=<MseLossBackward>)\n",
      "77 tensor(9.9819, grad_fn=<MseLossBackward>)\n",
      "78 tensor(9.5050, grad_fn=<MseLossBackward>)\n",
      "79 tensor(9.0525, grad_fn=<MseLossBackward>)\n",
      "80 tensor(8.6235, grad_fn=<MseLossBackward>)\n",
      "81 tensor(8.2166, grad_fn=<MseLossBackward>)\n",
      "82 tensor(7.8309, grad_fn=<MseLossBackward>)\n",
      "83 tensor(7.4643, grad_fn=<MseLossBackward>)\n",
      "84 tensor(7.1163, grad_fn=<MseLossBackward>)\n",
      "85 tensor(6.7858, grad_fn=<MseLossBackward>)\n",
      "86 tensor(6.4723, grad_fn=<MseLossBackward>)\n",
      "87 tensor(6.1749, grad_fn=<MseLossBackward>)\n",
      "88 tensor(5.8926, grad_fn=<MseLossBackward>)\n",
      "89 tensor(5.6238, grad_fn=<MseLossBackward>)\n",
      "90 tensor(5.3681, grad_fn=<MseLossBackward>)\n",
      "91 tensor(5.1249, grad_fn=<MseLossBackward>)\n",
      "92 tensor(4.8937, grad_fn=<MseLossBackward>)\n",
      "93 tensor(4.6736, grad_fn=<MseLossBackward>)\n",
      "94 tensor(4.4639, grad_fn=<MseLossBackward>)\n",
      "95 tensor(4.2643, grad_fn=<MseLossBackward>)\n",
      "96 tensor(4.0741, grad_fn=<MseLossBackward>)\n",
      "97 tensor(3.8927, grad_fn=<MseLossBackward>)\n",
      "98 tensor(3.7198, grad_fn=<MseLossBackward>)\n",
      "99 tensor(3.5551, grad_fn=<MseLossBackward>)\n",
      "100 tensor(3.3984, grad_fn=<MseLossBackward>)\n",
      "101 tensor(3.2491, grad_fn=<MseLossBackward>)\n",
      "102 tensor(3.1069, grad_fn=<MseLossBackward>)\n",
      "103 tensor(2.9714, grad_fn=<MseLossBackward>)\n",
      "104 tensor(2.8422, grad_fn=<MseLossBackward>)\n",
      "105 tensor(2.7189, grad_fn=<MseLossBackward>)\n",
      "106 tensor(2.6013, grad_fn=<MseLossBackward>)\n",
      "107 tensor(2.4890, grad_fn=<MseLossBackward>)\n",
      "108 tensor(2.3818, grad_fn=<MseLossBackward>)\n",
      "109 tensor(2.2795, grad_fn=<MseLossBackward>)\n",
      "110 tensor(2.1819, grad_fn=<MseLossBackward>)\n",
      "111 tensor(2.0888, grad_fn=<MseLossBackward>)\n",
      "112 tensor(1.9993, grad_fn=<MseLossBackward>)\n",
      "113 tensor(1.9138, grad_fn=<MseLossBackward>)\n",
      "114 tensor(1.8321, grad_fn=<MseLossBackward>)\n",
      "115 tensor(1.7541, grad_fn=<MseLossBackward>)\n",
      "116 tensor(1.6797, grad_fn=<MseLossBackward>)\n",
      "117 tensor(1.6086, grad_fn=<MseLossBackward>)\n",
      "118 tensor(1.5407, grad_fn=<MseLossBackward>)\n",
      "119 tensor(1.4758, grad_fn=<MseLossBackward>)\n",
      "120 tensor(1.4137, grad_fn=<MseLossBackward>)\n",
      "121 tensor(1.3543, grad_fn=<MseLossBackward>)\n",
      "122 tensor(1.2977, grad_fn=<MseLossBackward>)\n",
      "123 tensor(1.2435, grad_fn=<MseLossBackward>)\n",
      "124 tensor(1.1917, grad_fn=<MseLossBackward>)\n",
      "125 tensor(1.1421, grad_fn=<MseLossBackward>)\n",
      "126 tensor(1.0948, grad_fn=<MseLossBackward>)\n",
      "127 tensor(1.0494, grad_fn=<MseLossBackward>)\n",
      "128 tensor(1.0061, grad_fn=<MseLossBackward>)\n",
      "129 tensor(0.9646, grad_fn=<MseLossBackward>)\n",
      "130 tensor(0.9248, grad_fn=<MseLossBackward>)\n",
      "131 tensor(0.8868, grad_fn=<MseLossBackward>)\n",
      "132 tensor(0.8504, grad_fn=<MseLossBackward>)\n",
      "133 tensor(0.8156, grad_fn=<MseLossBackward>)\n",
      "134 tensor(0.7823, grad_fn=<MseLossBackward>)\n",
      "135 tensor(0.7503, grad_fn=<MseLossBackward>)\n",
      "136 tensor(0.7198, grad_fn=<MseLossBackward>)\n",
      "137 tensor(0.6906, grad_fn=<MseLossBackward>)\n",
      "138 tensor(0.6626, grad_fn=<MseLossBackward>)\n",
      "139 tensor(0.6359, grad_fn=<MseLossBackward>)\n",
      "140 tensor(0.6102, grad_fn=<MseLossBackward>)\n",
      "141 tensor(0.5856, grad_fn=<MseLossBackward>)\n",
      "142 tensor(0.5621, grad_fn=<MseLossBackward>)\n",
      "143 tensor(0.5396, grad_fn=<MseLossBackward>)\n",
      "144 tensor(0.5180, grad_fn=<MseLossBackward>)\n",
      "145 tensor(0.4973, grad_fn=<MseLossBackward>)\n",
      "146 tensor(0.4775, grad_fn=<MseLossBackward>)\n",
      "147 tensor(0.4585, grad_fn=<MseLossBackward>)\n",
      "148 tensor(0.4403, grad_fn=<MseLossBackward>)\n",
      "149 tensor(0.4228, grad_fn=<MseLossBackward>)\n",
      "150 tensor(0.4061, grad_fn=<MseLossBackward>)\n",
      "151 tensor(0.3900, grad_fn=<MseLossBackward>)\n",
      "152 tensor(0.3746, grad_fn=<MseLossBackward>)\n",
      "153 tensor(0.3598, grad_fn=<MseLossBackward>)\n",
      "154 tensor(0.3457, grad_fn=<MseLossBackward>)\n",
      "155 tensor(0.3321, grad_fn=<MseLossBackward>)\n",
      "156 tensor(0.3191, grad_fn=<MseLossBackward>)\n",
      "157 tensor(0.3066, grad_fn=<MseLossBackward>)\n",
      "158 tensor(0.2947, grad_fn=<MseLossBackward>)\n",
      "159 tensor(0.2832, grad_fn=<MseLossBackward>)\n",
      "160 tensor(0.2722, grad_fn=<MseLossBackward>)\n",
      "161 tensor(0.2617, grad_fn=<MseLossBackward>)\n",
      "162 tensor(0.2515, grad_fn=<MseLossBackward>)\n",
      "163 tensor(0.2418, grad_fn=<MseLossBackward>)\n",
      "164 tensor(0.2325, grad_fn=<MseLossBackward>)\n",
      "165 tensor(0.2235, grad_fn=<MseLossBackward>)\n",
      "166 tensor(0.2149, grad_fn=<MseLossBackward>)\n",
      "167 tensor(0.2067, grad_fn=<MseLossBackward>)\n",
      "168 tensor(0.1987, grad_fn=<MseLossBackward>)\n",
      "169 tensor(0.1911, grad_fn=<MseLossBackward>)\n",
      "170 tensor(0.1838, grad_fn=<MseLossBackward>)\n",
      "171 tensor(0.1768, grad_fn=<MseLossBackward>)\n",
      "172 tensor(0.1701, grad_fn=<MseLossBackward>)\n",
      "173 tensor(0.1636, grad_fn=<MseLossBackward>)\n",
      "174 tensor(0.1574, grad_fn=<MseLossBackward>)\n",
      "175 tensor(0.1514, grad_fn=<MseLossBackward>)\n",
      "176 tensor(0.1457, grad_fn=<MseLossBackward>)\n",
      "177 tensor(0.1402, grad_fn=<MseLossBackward>)\n",
      "178 tensor(0.1349, grad_fn=<MseLossBackward>)\n",
      "179 tensor(0.1298, grad_fn=<MseLossBackward>)\n",
      "180 tensor(0.1249, grad_fn=<MseLossBackward>)\n",
      "181 tensor(0.1203, grad_fn=<MseLossBackward>)\n",
      "182 tensor(0.1158, grad_fn=<MseLossBackward>)\n",
      "183 tensor(0.1114, grad_fn=<MseLossBackward>)\n",
      "184 tensor(0.1073, grad_fn=<MseLossBackward>)\n",
      "185 tensor(0.1033, grad_fn=<MseLossBackward>)\n",
      "186 tensor(0.0994, grad_fn=<MseLossBackward>)\n",
      "187 tensor(0.0957, grad_fn=<MseLossBackward>)\n",
      "188 tensor(0.0921, grad_fn=<MseLossBackward>)\n",
      "189 tensor(0.0887, grad_fn=<MseLossBackward>)\n",
      "190 tensor(0.0854, grad_fn=<MseLossBackward>)\n",
      "191 tensor(0.0823, grad_fn=<MseLossBackward>)\n",
      "192 tensor(0.0793, grad_fn=<MseLossBackward>)\n",
      "193 tensor(0.0763, grad_fn=<MseLossBackward>)\n",
      "194 tensor(0.0735, grad_fn=<MseLossBackward>)\n",
      "195 tensor(0.0708, grad_fn=<MseLossBackward>)\n",
      "196 tensor(0.0682, grad_fn=<MseLossBackward>)\n",
      "197 tensor(0.0657, grad_fn=<MseLossBackward>)\n",
      "198 tensor(0.0633, grad_fn=<MseLossBackward>)\n",
      "199 tensor(0.0610, grad_fn=<MseLossBackward>)\n",
      "200 tensor(0.0588, grad_fn=<MseLossBackward>)\n",
      "201 tensor(0.0566, grad_fn=<MseLossBackward>)\n",
      "202 tensor(0.0546, grad_fn=<MseLossBackward>)\n",
      "203 tensor(0.0526, grad_fn=<MseLossBackward>)\n",
      "204 tensor(0.0507, grad_fn=<MseLossBackward>)\n",
      "205 tensor(0.0489, grad_fn=<MseLossBackward>)\n",
      "206 tensor(0.0471, grad_fn=<MseLossBackward>)\n",
      "207 tensor(0.0454, grad_fn=<MseLossBackward>)\n",
      "208 tensor(0.0438, grad_fn=<MseLossBackward>)\n",
      "209 tensor(0.0422, grad_fn=<MseLossBackward>)\n",
      "210 tensor(0.0407, grad_fn=<MseLossBackward>)\n",
      "211 tensor(0.0392, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212 tensor(0.0378, grad_fn=<MseLossBackward>)\n",
      "213 tensor(0.0365, grad_fn=<MseLossBackward>)\n",
      "214 tensor(0.0351, grad_fn=<MseLossBackward>)\n",
      "215 tensor(0.0339, grad_fn=<MseLossBackward>)\n",
      "216 tensor(0.0327, grad_fn=<MseLossBackward>)\n",
      "217 tensor(0.0315, grad_fn=<MseLossBackward>)\n",
      "218 tensor(0.0304, grad_fn=<MseLossBackward>)\n",
      "219 tensor(0.0293, grad_fn=<MseLossBackward>)\n",
      "220 tensor(0.0283, grad_fn=<MseLossBackward>)\n",
      "221 tensor(0.0273, grad_fn=<MseLossBackward>)\n",
      "222 tensor(0.0263, grad_fn=<MseLossBackward>)\n",
      "223 tensor(0.0254, grad_fn=<MseLossBackward>)\n",
      "224 tensor(0.0245, grad_fn=<MseLossBackward>)\n",
      "225 tensor(0.0236, grad_fn=<MseLossBackward>)\n",
      "226 tensor(0.0228, grad_fn=<MseLossBackward>)\n",
      "227 tensor(0.0220, grad_fn=<MseLossBackward>)\n",
      "228 tensor(0.0212, grad_fn=<MseLossBackward>)\n",
      "229 tensor(0.0205, grad_fn=<MseLossBackward>)\n",
      "230 tensor(0.0198, grad_fn=<MseLossBackward>)\n",
      "231 tensor(0.0191, grad_fn=<MseLossBackward>)\n",
      "232 tensor(0.0184, grad_fn=<MseLossBackward>)\n",
      "233 tensor(0.0178, grad_fn=<MseLossBackward>)\n",
      "234 tensor(0.0172, grad_fn=<MseLossBackward>)\n",
      "235 tensor(0.0166, grad_fn=<MseLossBackward>)\n",
      "236 tensor(0.0160, grad_fn=<MseLossBackward>)\n",
      "237 tensor(0.0154, grad_fn=<MseLossBackward>)\n",
      "238 tensor(0.0149, grad_fn=<MseLossBackward>)\n",
      "239 tensor(0.0144, grad_fn=<MseLossBackward>)\n",
      "240 tensor(0.0139, grad_fn=<MseLossBackward>)\n",
      "241 tensor(0.0134, grad_fn=<MseLossBackward>)\n",
      "242 tensor(0.0130, grad_fn=<MseLossBackward>)\n",
      "243 tensor(0.0125, grad_fn=<MseLossBackward>)\n",
      "244 tensor(0.0121, grad_fn=<MseLossBackward>)\n",
      "245 tensor(0.0117, grad_fn=<MseLossBackward>)\n",
      "246 tensor(0.0113, grad_fn=<MseLossBackward>)\n",
      "247 tensor(0.0109, grad_fn=<MseLossBackward>)\n",
      "248 tensor(0.0105, grad_fn=<MseLossBackward>)\n",
      "249 tensor(0.0102, grad_fn=<MseLossBackward>)\n",
      "250 tensor(0.0098, grad_fn=<MseLossBackward>)\n",
      "251 tensor(0.0095, grad_fn=<MseLossBackward>)\n",
      "252 tensor(0.0092, grad_fn=<MseLossBackward>)\n",
      "253 tensor(0.0089, grad_fn=<MseLossBackward>)\n",
      "254 tensor(0.0086, grad_fn=<MseLossBackward>)\n",
      "255 tensor(0.0083, grad_fn=<MseLossBackward>)\n",
      "256 tensor(0.0080, grad_fn=<MseLossBackward>)\n",
      "257 tensor(0.0077, grad_fn=<MseLossBackward>)\n",
      "258 tensor(0.0075, grad_fn=<MseLossBackward>)\n",
      "259 tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "260 tensor(0.0070, grad_fn=<MseLossBackward>)\n",
      "261 tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "262 tensor(0.0065, grad_fn=<MseLossBackward>)\n",
      "263 tensor(0.0063, grad_fn=<MseLossBackward>)\n",
      "264 tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "265 tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "266 tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "267 tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "268 tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "269 tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "270 tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "271 tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "272 tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "273 tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "274 tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "275 tensor(0.0042, grad_fn=<MseLossBackward>)\n",
      "276 tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "277 tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "278 tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "279 tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "280 tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "281 tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "282 tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "283 tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "284 tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "285 tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "286 tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "287 tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "288 tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "289 tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "290 tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "291 tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "292 tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "293 tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "294 tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "295 tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "296 tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "297 tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "298 tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "299 tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "300 tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "301 tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "302 tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "303 tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "304 tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "305 tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "306 tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "307 tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "308 tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "309 tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "310 tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "311 tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "312 tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "313 tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "314 tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "315 tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "316 tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "317 tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "318 tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "319 tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "320 tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "321 tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "322 tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "323 tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "324 tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "325 tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "326 tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "327 tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "328 tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "329 tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "330 tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "331 tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "332 tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "333 tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "334 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "335 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "336 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "337 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "338 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "339 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "340 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "341 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "342 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "343 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "344 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "345 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "346 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "347 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "348 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "349 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "350 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "351 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "352 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "353 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "354 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "355 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "356 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "357 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "358 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "359 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "360 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "361 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "362 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "363 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "364 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "365 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "366 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "367 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "368 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "369 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "370 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "371 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "372 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "373 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "374 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "375 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "376 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "377 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "378 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "379 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "380 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "381 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "382 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "383 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "384 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "385 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "386 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "387 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "388 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "389 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "390 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "391 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "392 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "393 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "394 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "395 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "396 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "397 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "398 tensor(9.8310e-05, grad_fn=<MseLossBackward>)\n",
      "399 tensor(9.5553e-05, grad_fn=<MseLossBackward>)\n",
      "400 tensor(9.2881e-05, grad_fn=<MseLossBackward>)\n",
      "401 tensor(9.0278e-05, grad_fn=<MseLossBackward>)\n",
      "402 tensor(8.7756e-05, grad_fn=<MseLossBackward>)\n",
      "403 tensor(8.5306e-05, grad_fn=<MseLossBackward>)\n",
      "404 tensor(8.2924e-05, grad_fn=<MseLossBackward>)\n",
      "405 tensor(8.0610e-05, grad_fn=<MseLossBackward>)\n",
      "406 tensor(7.8366e-05, grad_fn=<MseLossBackward>)\n",
      "407 tensor(7.6187e-05, grad_fn=<MseLossBackward>)\n",
      "408 tensor(7.4070e-05, grad_fn=<MseLossBackward>)\n",
      "409 tensor(7.2010e-05, grad_fn=<MseLossBackward>)\n",
      "410 tensor(7.0013e-05, grad_fn=<MseLossBackward>)\n",
      "411 tensor(6.8071e-05, grad_fn=<MseLossBackward>)\n",
      "412 tensor(6.6183e-05, grad_fn=<MseLossBackward>)\n",
      "413 tensor(6.4355e-05, grad_fn=<MseLossBackward>)\n",
      "414 tensor(6.2573e-05, grad_fn=<MseLossBackward>)\n",
      "415 tensor(6.0844e-05, grad_fn=<MseLossBackward>)\n",
      "416 tensor(5.9167e-05, grad_fn=<MseLossBackward>)\n",
      "417 tensor(5.7534e-05, grad_fn=<MseLossBackward>)\n",
      "418 tensor(5.5949e-05, grad_fn=<MseLossBackward>)\n",
      "419 tensor(5.4410e-05, grad_fn=<MseLossBackward>)\n",
      "420 tensor(5.2911e-05, grad_fn=<MseLossBackward>)\n",
      "421 tensor(5.1458e-05, grad_fn=<MseLossBackward>)\n",
      "422 tensor(5.0044e-05, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423 tensor(4.8672e-05, grad_fn=<MseLossBackward>)\n",
      "424 tensor(4.7336e-05, grad_fn=<MseLossBackward>)\n",
      "425 tensor(4.6039e-05, grad_fn=<MseLossBackward>)\n",
      "426 tensor(4.4778e-05, grad_fn=<MseLossBackward>)\n",
      "427 tensor(4.3554e-05, grad_fn=<MseLossBackward>)\n",
      "428 tensor(4.2364e-05, grad_fn=<MseLossBackward>)\n",
      "429 tensor(4.1207e-05, grad_fn=<MseLossBackward>)\n",
      "430 tensor(4.0083e-05, grad_fn=<MseLossBackward>)\n",
      "431 tensor(3.8990e-05, grad_fn=<MseLossBackward>)\n",
      "432 tensor(3.7928e-05, grad_fn=<MseLossBackward>)\n",
      "433 tensor(3.6894e-05, grad_fn=<MseLossBackward>)\n",
      "434 tensor(3.5889e-05, grad_fn=<MseLossBackward>)\n",
      "435 tensor(3.4916e-05, grad_fn=<MseLossBackward>)\n",
      "436 tensor(3.3969e-05, grad_fn=<MseLossBackward>)\n",
      "437 tensor(3.3046e-05, grad_fn=<MseLossBackward>)\n",
      "438 tensor(3.2151e-05, grad_fn=<MseLossBackward>)\n",
      "439 tensor(3.1280e-05, grad_fn=<MseLossBackward>)\n",
      "440 tensor(3.0433e-05, grad_fn=<MseLossBackward>)\n",
      "441 tensor(2.9610e-05, grad_fn=<MseLossBackward>)\n",
      "442 tensor(2.8810e-05, grad_fn=<MseLossBackward>)\n",
      "443 tensor(2.8031e-05, grad_fn=<MseLossBackward>)\n",
      "444 tensor(2.7275e-05, grad_fn=<MseLossBackward>)\n",
      "445 tensor(2.6538e-05, grad_fn=<MseLossBackward>)\n",
      "446 tensor(2.5825e-05, grad_fn=<MseLossBackward>)\n",
      "447 tensor(2.5129e-05, grad_fn=<MseLossBackward>)\n",
      "448 tensor(2.4453e-05, grad_fn=<MseLossBackward>)\n",
      "449 tensor(2.3794e-05, grad_fn=<MseLossBackward>)\n",
      "450 tensor(2.3156e-05, grad_fn=<MseLossBackward>)\n",
      "451 tensor(2.2533e-05, grad_fn=<MseLossBackward>)\n",
      "452 tensor(2.1930e-05, grad_fn=<MseLossBackward>)\n",
      "453 tensor(2.1342e-05, grad_fn=<MseLossBackward>)\n",
      "454 tensor(2.0770e-05, grad_fn=<MseLossBackward>)\n",
      "455 tensor(2.0214e-05, grad_fn=<MseLossBackward>)\n",
      "456 tensor(1.9672e-05, grad_fn=<MseLossBackward>)\n",
      "457 tensor(1.9146e-05, grad_fn=<MseLossBackward>)\n",
      "458 tensor(1.8634e-05, grad_fn=<MseLossBackward>)\n",
      "459 tensor(1.8138e-05, grad_fn=<MseLossBackward>)\n",
      "460 tensor(1.7653e-05, grad_fn=<MseLossBackward>)\n",
      "461 tensor(1.7182e-05, grad_fn=<MseLossBackward>)\n",
      "462 tensor(1.6725e-05, grad_fn=<MseLossBackward>)\n",
      "463 tensor(1.6280e-05, grad_fn=<MseLossBackward>)\n",
      "464 tensor(1.5847e-05, grad_fn=<MseLossBackward>)\n",
      "465 tensor(1.5426e-05, grad_fn=<MseLossBackward>)\n",
      "466 tensor(1.5014e-05, grad_fn=<MseLossBackward>)\n",
      "467 tensor(1.4616e-05, grad_fn=<MseLossBackward>)\n",
      "468 tensor(1.4230e-05, grad_fn=<MseLossBackward>)\n",
      "469 tensor(1.3851e-05, grad_fn=<MseLossBackward>)\n",
      "470 tensor(1.3484e-05, grad_fn=<MseLossBackward>)\n",
      "471 tensor(1.3128e-05, grad_fn=<MseLossBackward>)\n",
      "472 tensor(1.2779e-05, grad_fn=<MseLossBackward>)\n",
      "473 tensor(1.2441e-05, grad_fn=<MseLossBackward>)\n",
      "474 tensor(1.2112e-05, grad_fn=<MseLossBackward>)\n",
      "475 tensor(1.1793e-05, grad_fn=<MseLossBackward>)\n",
      "476 tensor(1.1481e-05, grad_fn=<MseLossBackward>)\n",
      "477 tensor(1.1179e-05, grad_fn=<MseLossBackward>)\n",
      "478 tensor(1.0883e-05, grad_fn=<MseLossBackward>)\n",
      "479 tensor(1.0596e-05, grad_fn=<MseLossBackward>)\n",
      "480 tensor(1.0317e-05, grad_fn=<MseLossBackward>)\n",
      "481 tensor(1.0044e-05, grad_fn=<MseLossBackward>)\n",
      "482 tensor(9.7816e-06, grad_fn=<MseLossBackward>)\n",
      "483 tensor(9.5244e-06, grad_fn=<MseLossBackward>)\n",
      "484 tensor(9.2742e-06, grad_fn=<MseLossBackward>)\n",
      "485 tensor(9.0309e-06, grad_fn=<MseLossBackward>)\n",
      "486 tensor(8.7937e-06, grad_fn=<MseLossBackward>)\n",
      "487 tensor(8.5629e-06, grad_fn=<MseLossBackward>)\n",
      "488 tensor(8.3382e-06, grad_fn=<MseLossBackward>)\n",
      "489 tensor(8.1198e-06, grad_fn=<MseLossBackward>)\n",
      "490 tensor(7.9073e-06, grad_fn=<MseLossBackward>)\n",
      "491 tensor(7.7006e-06, grad_fn=<MseLossBackward>)\n",
      "492 tensor(7.4987e-06, grad_fn=<MseLossBackward>)\n",
      "493 tensor(7.3030e-06, grad_fn=<MseLossBackward>)\n",
      "494 tensor(7.1121e-06, grad_fn=<MseLossBackward>)\n",
      "495 tensor(6.9259e-06, grad_fn=<MseLossBackward>)\n",
      "496 tensor(6.7448e-06, grad_fn=<MseLossBackward>)\n",
      "497 tensor(6.5699e-06, grad_fn=<MseLossBackward>)\n",
      "498 tensor(6.3983e-06, grad_fn=<MseLossBackward>)\n",
      "499 tensor(6.2317e-06, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "for t in range(500):\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(6.0695e-06, grad_fn=<MseLossBackward>)\n",
      "1 tensor(0.0436, grad_fn=<MseLossBackward>)\n",
      "2 tensor(0.0338, grad_fn=<MseLossBackward>)\n",
      "3 tensor(0.0193, grad_fn=<MseLossBackward>)\n",
      "4 tensor(0.0178, grad_fn=<MseLossBackward>)\n",
      "5 tensor(0.0182, grad_fn=<MseLossBackward>)\n",
      "6 tensor(0.0148, grad_fn=<MseLossBackward>)\n",
      "7 tensor(0.0116, grad_fn=<MseLossBackward>)\n",
      "8 tensor(0.0105, grad_fn=<MseLossBackward>)\n",
      "9 tensor(0.0096, grad_fn=<MseLossBackward>)\n",
      "10 tensor(0.0081, grad_fn=<MseLossBackward>)\n",
      "11 tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "12 tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "13 tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "14 tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "15 tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "16 tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "17 tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "18 tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "19 tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "20 tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "21 tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "22 tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "23 tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "24 tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "25 tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "26 tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "27 tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "28 tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "29 tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "30 tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "31 tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "32 tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "33 tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "34 tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "35 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "36 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "37 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "38 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "39 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "40 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "41 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "42 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "43 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "44 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "45 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "46 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "47 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "48 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "49 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "50 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "51 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "52 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "53 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "54 tensor(8.2607e-05, grad_fn=<MseLossBackward>)\n",
      "55 tensor(5.8303e-05, grad_fn=<MseLossBackward>)\n",
      "56 tensor(5.9084e-05, grad_fn=<MseLossBackward>)\n",
      "57 tensor(6.8763e-05, grad_fn=<MseLossBackward>)\n",
      "58 tensor(6.8670e-05, grad_fn=<MseLossBackward>)\n",
      "59 tensor(6.4455e-05, grad_fn=<MseLossBackward>)\n",
      "60 tensor(5.6016e-05, grad_fn=<MseLossBackward>)\n",
      "61 tensor(4.1466e-05, grad_fn=<MseLossBackward>)\n",
      "62 tensor(3.1479e-05, grad_fn=<MseLossBackward>)\n",
      "63 tensor(2.9971e-05, grad_fn=<MseLossBackward>)\n",
      "64 tensor(3.1651e-05, grad_fn=<MseLossBackward>)\n",
      "65 tensor(3.2784e-05, grad_fn=<MseLossBackward>)\n",
      "66 tensor(3.1899e-05, grad_fn=<MseLossBackward>)\n",
      "67 tensor(2.7108e-05, grad_fn=<MseLossBackward>)\n",
      "68 tensor(2.0624e-05, grad_fn=<MseLossBackward>)\n",
      "69 tensor(1.6674e-05, grad_fn=<MseLossBackward>)\n",
      "70 tensor(1.5407e-05, grad_fn=<MseLossBackward>)\n",
      "71 tensor(1.6305e-05, grad_fn=<MseLossBackward>)\n",
      "72 tensor(1.5889e-05, grad_fn=<MseLossBackward>)\n",
      "73 tensor(1.3596e-05, grad_fn=<MseLossBackward>)\n",
      "74 tensor(1.2449e-05, grad_fn=<MseLossBackward>)\n",
      "75 tensor(1.1496e-05, grad_fn=<MseLossBackward>)\n",
      "76 tensor(9.4959e-06, grad_fn=<MseLossBackward>)\n",
      "77 tensor(8.1945e-06, grad_fn=<MseLossBackward>)\n",
      "78 tensor(7.0440e-06, grad_fn=<MseLossBackward>)\n",
      "79 tensor(6.2492e-06, grad_fn=<MseLossBackward>)\n",
      "80 tensor(7.0426e-06, grad_fn=<MseLossBackward>)\n",
      "81 tensor(7.4944e-06, grad_fn=<MseLossBackward>)\n",
      "82 tensor(5.9063e-06, grad_fn=<MseLossBackward>)\n",
      "83 tensor(3.9106e-06, grad_fn=<MseLossBackward>)\n",
      "84 tensor(3.1695e-06, grad_fn=<MseLossBackward>)\n",
      "85 tensor(3.6366e-06, grad_fn=<MseLossBackward>)\n",
      "86 tensor(4.2374e-06, grad_fn=<MseLossBackward>)\n",
      "87 tensor(3.7669e-06, grad_fn=<MseLossBackward>)\n",
      "88 tensor(2.7334e-06, grad_fn=<MseLossBackward>)\n",
      "89 tensor(2.1845e-06, grad_fn=<MseLossBackward>)\n",
      "90 tensor(2.3151e-06, grad_fn=<MseLossBackward>)\n",
      "91 tensor(2.3728e-06, grad_fn=<MseLossBackward>)\n",
      "92 tensor(1.8968e-06, grad_fn=<MseLossBackward>)\n",
      "93 tensor(1.4663e-06, grad_fn=<MseLossBackward>)\n",
      "94 tensor(1.4735e-06, grad_fn=<MseLossBackward>)\n",
      "95 tensor(1.5895e-06, grad_fn=<MseLossBackward>)\n",
      "96 tensor(1.4994e-06, grad_fn=<MseLossBackward>)\n",
      "97 tensor(1.1745e-06, grad_fn=<MseLossBackward>)\n",
      "98 tensor(8.3466e-07, grad_fn=<MseLossBackward>)\n",
      "99 tensor(7.1891e-07, grad_fn=<MseLossBackward>)\n",
      "100 tensor(8.5929e-07, grad_fn=<MseLossBackward>)\n",
      "101 tensor(9.9745e-07, grad_fn=<MseLossBackward>)\n",
      "102 tensor(7.9784e-07, grad_fn=<MseLossBackward>)\n",
      "103 tensor(4.9686e-07, grad_fn=<MseLossBackward>)\n",
      "104 tensor(4.7013e-07, grad_fn=<MseLossBackward>)\n",
      "105 tensor(5.2690e-07, grad_fn=<MseLossBackward>)\n",
      "106 tensor(4.7068e-07, grad_fn=<MseLossBackward>)\n",
      "107 tensor(4.0525e-07, grad_fn=<MseLossBackward>)\n",
      "108 tensor(3.8218e-07, grad_fn=<MseLossBackward>)\n",
      "109 tensor(3.7670e-07, grad_fn=<MseLossBackward>)\n",
      "110 tensor(3.2214e-07, grad_fn=<MseLossBackward>)\n",
      "111 tensor(2.3031e-07, grad_fn=<MseLossBackward>)\n",
      "112 tensor(1.9793e-07, grad_fn=<MseLossBackward>)\n",
      "113 tensor(2.2942e-07, grad_fn=<MseLossBackward>)\n",
      "114 tensor(2.4704e-07, grad_fn=<MseLossBackward>)\n",
      "115 tensor(2.0970e-07, grad_fn=<MseLossBackward>)\n",
      "116 tensor(1.4479e-07, grad_fn=<MseLossBackward>)\n",
      "117 tensor(1.2413e-07, grad_fn=<MseLossBackward>)\n",
      "118 tensor(1.2524e-07, grad_fn=<MseLossBackward>)\n",
      "119 tensor(1.2712e-07, grad_fn=<MseLossBackward>)\n",
      "120 tensor(1.2183e-07, grad_fn=<MseLossBackward>)\n",
      "121 tensor(1.0133e-07, grad_fn=<MseLossBackward>)\n",
      "122 tensor(8.7405e-08, grad_fn=<MseLossBackward>)\n",
      "123 tensor(8.0010e-08, grad_fn=<MseLossBackward>)\n",
      "124 tensor(6.5893e-08, grad_fn=<MseLossBackward>)\n",
      "125 tensor(5.9931e-08, grad_fn=<MseLossBackward>)\n",
      "126 tensor(6.1764e-08, grad_fn=<MseLossBackward>)\n",
      "127 tensor(6.1554e-08, grad_fn=<MseLossBackward>)\n",
      "128 tensor(5.4879e-08, grad_fn=<MseLossBackward>)\n",
      "129 tensor(3.7834e-08, grad_fn=<MseLossBackward>)\n",
      "130 tensor(3.5376e-08, grad_fn=<MseLossBackward>)\n",
      "131 tensor(4.2591e-08, grad_fn=<MseLossBackward>)\n",
      "132 tensor(4.7533e-08, grad_fn=<MseLossBackward>)\n",
      "133 tensor(5.9782e-08, grad_fn=<MseLossBackward>)\n",
      "134 tensor(9.0053e-08, grad_fn=<MseLossBackward>)\n",
      "135 tensor(1.7500e-07, grad_fn=<MseLossBackward>)\n",
      "136 tensor(3.9866e-07, grad_fn=<MseLossBackward>)\n",
      "137 tensor(9.7684e-07, grad_fn=<MseLossBackward>)\n",
      "138 tensor(2.5193e-06, grad_fn=<MseLossBackward>)\n",
      "139 tensor(6.7504e-06, grad_fn=<MseLossBackward>)\n",
      "140 tensor(1.8594e-05, grad_fn=<MseLossBackward>)\n",
      "141 tensor(5.2036e-05, grad_fn=<MseLossBackward>)\n",
      "142 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "143 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "144 tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "145 tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "146 tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "147 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "148 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "149 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "150 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "151 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "152 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "153 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "154 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "155 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "156 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "157 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "158 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "159 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "160 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "161 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "162 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "163 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "164 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "165 tensor(8.2313e-05, grad_fn=<MseLossBackward>)\n",
      "166 tensor(6.5818e-05, grad_fn=<MseLossBackward>)\n",
      "167 tensor(8.7034e-05, grad_fn=<MseLossBackward>)\n",
      "168 tensor(6.9949e-05, grad_fn=<MseLossBackward>)\n",
      "169 tensor(5.0725e-05, grad_fn=<MseLossBackward>)\n",
      "170 tensor(6.3129e-05, grad_fn=<MseLossBackward>)\n",
      "171 tensor(5.7342e-05, grad_fn=<MseLossBackward>)\n",
      "172 tensor(3.6679e-05, grad_fn=<MseLossBackward>)\n",
      "173 tensor(4.0017e-05, grad_fn=<MseLossBackward>)\n",
      "174 tensor(4.3896e-05, grad_fn=<MseLossBackward>)\n",
      "175 tensor(3.3744e-05, grad_fn=<MseLossBackward>)\n",
      "176 tensor(3.0496e-05, grad_fn=<MseLossBackward>)\n",
      "177 tensor(3.1397e-05, grad_fn=<MseLossBackward>)\n",
      "178 tensor(2.6948e-05, grad_fn=<MseLossBackward>)\n",
      "179 tensor(2.3532e-05, grad_fn=<MseLossBackward>)\n",
      "180 tensor(2.1760e-05, grad_fn=<MseLossBackward>)\n",
      "181 tensor(1.8647e-05, grad_fn=<MseLossBackward>)\n",
      "182 tensor(1.7770e-05, grad_fn=<MseLossBackward>)\n",
      "183 tensor(1.9303e-05, grad_fn=<MseLossBackward>)\n",
      "184 tensor(1.8559e-05, grad_fn=<MseLossBackward>)\n",
      "185 tensor(1.6469e-05, grad_fn=<MseLossBackward>)\n",
      "186 tensor(1.5605e-05, grad_fn=<MseLossBackward>)\n",
      "187 tensor(1.3566e-05, grad_fn=<MseLossBackward>)\n",
      "188 tensor(1.1016e-05, grad_fn=<MseLossBackward>)\n",
      "189 tensor(1.1082e-05, grad_fn=<MseLossBackward>)\n",
      "190 tensor(1.2426e-05, grad_fn=<MseLossBackward>)\n",
      "191 tensor(1.3472e-05, grad_fn=<MseLossBackward>)\n",
      "192 tensor(1.7627e-05, grad_fn=<MseLossBackward>)\n",
      "193 tensor(2.8031e-05, grad_fn=<MseLossBackward>)\n",
      "194 tensor(4.7068e-05, grad_fn=<MseLossBackward>)\n",
      "195 tensor(8.2859e-05, grad_fn=<MseLossBackward>)\n",
      "196 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "197 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "198 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "199 tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "200 tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "201 tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "202 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "203 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "204 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "205 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "206 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "207 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "208 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "209 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "210 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "211 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "212 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "213 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "214 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "215 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "216 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "217 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "218 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "219 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "220 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "221 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "222 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "223 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "224 tensor(9.1779e-05, grad_fn=<MseLossBackward>)\n",
      "225 tensor(7.3112e-05, grad_fn=<MseLossBackward>)\n",
      "226 tensor(6.0744e-05, grad_fn=<MseLossBackward>)\n",
      "227 tensor(5.6843e-05, grad_fn=<MseLossBackward>)\n",
      "228 tensor(5.6486e-05, grad_fn=<MseLossBackward>)\n",
      "229 tensor(5.5647e-05, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230 tensor(5.5534e-05, grad_fn=<MseLossBackward>)\n",
      "231 tensor(5.8706e-05, grad_fn=<MseLossBackward>)\n",
      "232 tensor(6.4321e-05, grad_fn=<MseLossBackward>)\n",
      "233 tensor(6.9538e-05, grad_fn=<MseLossBackward>)\n",
      "234 tensor(7.4985e-05, grad_fn=<MseLossBackward>)\n",
      "235 tensor(8.7146e-05, grad_fn=<MseLossBackward>)\n",
      "236 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "237 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "238 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "239 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "240 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "241 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "242 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "243 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "244 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "245 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "246 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "247 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "248 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "249 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "250 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "251 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "252 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "253 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "254 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "255 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "256 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "257 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "258 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "259 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "260 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "261 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "262 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "263 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "264 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "265 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "266 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "267 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "268 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "269 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "270 tensor(8.7725e-05, grad_fn=<MseLossBackward>)\n",
      "271 tensor(7.2545e-05, grad_fn=<MseLossBackward>)\n",
      "272 tensor(8.0713e-05, grad_fn=<MseLossBackward>)\n",
      "273 tensor(9.8497e-05, grad_fn=<MseLossBackward>)\n",
      "274 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "275 tensor(9.8677e-05, grad_fn=<MseLossBackward>)\n",
      "276 tensor(7.8682e-05, grad_fn=<MseLossBackward>)\n",
      "277 tensor(6.0796e-05, grad_fn=<MseLossBackward>)\n",
      "278 tensor(5.4849e-05, grad_fn=<MseLossBackward>)\n",
      "279 tensor(6.1097e-05, grad_fn=<MseLossBackward>)\n",
      "280 tensor(7.2454e-05, grad_fn=<MseLossBackward>)\n",
      "281 tensor(8.1148e-05, grad_fn=<MseLossBackward>)\n",
      "282 tensor(8.4221e-05, grad_fn=<MseLossBackward>)\n",
      "283 tensor(8.4682e-05, grad_fn=<MseLossBackward>)\n",
      "284 tensor(8.8749e-05, grad_fn=<MseLossBackward>)\n",
      "285 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "286 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "287 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "288 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "289 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "290 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "291 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "292 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "293 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "294 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "295 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "296 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "297 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "298 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "299 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "300 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "301 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "302 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "303 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "304 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "305 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "306 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "307 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "308 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "309 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "310 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "311 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "312 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "313 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "314 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "315 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "316 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "317 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "318 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "319 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "320 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "321 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "322 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "323 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "324 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "325 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "326 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "327 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "328 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "329 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "330 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "331 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "332 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "333 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "334 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "335 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "336 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "337 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "338 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "339 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "340 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "341 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "342 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "343 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "344 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "345 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "346 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "347 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "348 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "349 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "350 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "351 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "352 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "353 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "354 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "355 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "356 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "357 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "358 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "359 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "360 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "361 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "362 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "363 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "364 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "365 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "366 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "367 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "368 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "369 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "370 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "371 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "372 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "373 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "374 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "375 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "376 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "377 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "378 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "379 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "380 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "381 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "382 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "383 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "384 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "385 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "386 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "387 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "388 tensor(9.6111e-05, grad_fn=<MseLossBackward>)\n",
      "389 tensor(8.3628e-05, grad_fn=<MseLossBackward>)\n",
      "390 tensor(8.4718e-05, grad_fn=<MseLossBackward>)\n",
      "391 tensor(9.7198e-05, grad_fn=<MseLossBackward>)\n",
      "392 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "393 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "394 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "395 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "396 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "397 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "398 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "399 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "400 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "401 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "402 tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "403 tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "404 tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "405 tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "406 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "407 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "408 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "409 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "410 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "411 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "412 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "413 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "414 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "415 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "416 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "417 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "418 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "419 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "420 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "421 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "422 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "423 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "424 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "425 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "426 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "427 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "428 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "429 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "430 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "431 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "432 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "433 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "434 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "435 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "436 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "437 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "438 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "439 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "440 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "441 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "442 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "443 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "444 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "445 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "446 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "447 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "448 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "449 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "450 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "451 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "452 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "453 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "454 tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "455 tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "456 tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "457 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "458 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "459 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "460 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "461 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "462 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "463 tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "464 tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "465 tensor(0.0005, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "467 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "468 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "469 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "470 tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "471 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "472 tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "473 tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "474 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "475 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "476 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "477 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "478 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "479 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "480 tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "481 tensor(9.1654e-05, grad_fn=<MseLossBackward>)\n",
      "482 tensor(8.3573e-05, grad_fn=<MseLossBackward>)\n",
      "483 tensor(7.8779e-05, grad_fn=<MseLossBackward>)\n",
      "484 tensor(7.4335e-05, grad_fn=<MseLossBackward>)\n",
      "485 tensor(6.9345e-05, grad_fn=<MseLossBackward>)\n",
      "486 tensor(6.5429e-05, grad_fn=<MseLossBackward>)\n",
      "487 tensor(6.4420e-05, grad_fn=<MseLossBackward>)\n",
      "488 tensor(6.5930e-05, grad_fn=<MseLossBackward>)\n",
      "489 tensor(6.7135e-05, grad_fn=<MseLossBackward>)\n",
      "490 tensor(6.4930e-05, grad_fn=<MseLossBackward>)\n",
      "491 tensor(5.8440e-05, grad_fn=<MseLossBackward>)\n",
      "492 tensor(4.9968e-05, grad_fn=<MseLossBackward>)\n",
      "493 tensor(4.3699e-05, grad_fn=<MseLossBackward>)\n",
      "494 tensor(4.3305e-05, grad_fn=<MseLossBackward>)\n",
      "495 tensor(5.0099e-05, grad_fn=<MseLossBackward>)\n",
      "496 tensor(6.2858e-05, grad_fn=<MseLossBackward>)\n",
      "497 tensor(7.9227e-05, grad_fn=<MseLossBackward>)\n",
      "498 tensor(9.7660e-05, grad_fn=<MseLossBackward>)\n",
      "499 tensor(0.0001, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for t in range(500):\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "class DynamicNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(DynamicNet, self).__init__()\n",
    "        self.input_linear = torch.nn.Linear(D_in, H)\n",
    "        self.middle_linear = torch.nn.Linear(H, H)\n",
    "        self.output_linear = torch.nn.Linear(H, D_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_relu = self.input_linear(x).clamp(min=0)\n",
    "        for _ in range(random.randint(0, 3)):\n",
    "            h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
    "        y_pred = self.output_linear(h_relu)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DynamicNet(D_in, H, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 663.366943359375\n",
      "1 718.9990844726562\n",
      "2 662.370361328125\n",
      "3 661.5233154296875\n",
      "4 659.7084350585938\n",
      "5 659.5391845703125\n",
      "6 666.0862426757812\n",
      "7 655.28271484375\n",
      "8 653.4010009765625\n",
      "9 484.8774108886719\n",
      "10 655.8026733398438\n",
      "11 422.943115234375\n",
      "12 649.2090454101562\n",
      "13 654.6929931640625\n",
      "14 613.3915405273438\n",
      "15 653.62109375\n",
      "16 642.416748046875\n",
      "17 639.1163330078125\n",
      "18 650.7113037109375\n",
      "19 567.915771484375\n",
      "20 552.3798217773438\n",
      "21 213.92726135253906\n",
      "22 642.9793090820312\n",
      "23 177.522705078125\n",
      "24 598.2315063476562\n",
      "25 632.1116333007812\n",
      "26 119.21827697753906\n",
      "27 564.61376953125\n",
      "28 548.3639526367188\n",
      "29 598.5641479492188\n",
      "30 502.9178466796875\n",
      "31 73.6573715209961\n",
      "32 68.23778533935547\n",
      "33 304.8495178222656\n",
      "34 279.8722229003906\n",
      "35 478.75823974609375\n",
      "36 220.2909698486328\n",
      "37 311.8450622558594\n",
      "38 169.48216247558594\n",
      "39 250.71420288085938\n",
      "40 149.9703369140625\n",
      "41 299.0675964355469\n",
      "42 127.45833587646484\n",
      "43 262.2038879394531\n",
      "44 218.76390075683594\n",
      "45 198.59788513183594\n",
      "46 142.89097595214844\n",
      "47 109.01383209228516\n",
      "48 224.3277130126953\n",
      "49 151.96981811523438\n",
      "50 124.3051528930664\n",
      "51 164.29554748535156\n",
      "52 90.81977081298828\n",
      "53 95.44415283203125\n",
      "54 169.20938110351562\n",
      "55 78.5374755859375\n",
      "56 85.3929672241211\n",
      "57 138.71876525878906\n",
      "58 128.89364624023438\n",
      "59 115.03693389892578\n",
      "60 81.63423156738281\n",
      "61 109.740234375\n",
      "62 45.99490737915039\n",
      "63 81.0319595336914\n",
      "64 53.53255081176758\n",
      "65 45.25070571899414\n",
      "66 40.25110626220703\n",
      "67 50.76675033569336\n",
      "68 59.126487731933594\n",
      "69 38.06201934814453\n",
      "70 112.74626159667969\n",
      "71 66.7024917602539\n",
      "72 58.619956970214844\n",
      "73 30.651819229125977\n",
      "74 50.22672653198242\n",
      "75 87.11261749267578\n",
      "76 47.468177795410156\n",
      "77 18.765443801879883\n",
      "78 31.599882125854492\n",
      "79 46.14014434814453\n",
      "80 22.89218521118164\n",
      "81 18.79808807373047\n",
      "82 22.34962272644043\n",
      "83 19.216833114624023\n",
      "84 38.833011627197266\n",
      "85 15.613865852355957\n",
      "86 27.680105209350586\n",
      "87 22.74256134033203\n",
      "88 14.95281982421875\n",
      "89 15.977853775024414\n",
      "90 16.312145233154297\n",
      "91 12.980587005615234\n",
      "92 47.38347625732422\n",
      "93 13.361571311950684\n",
      "94 45.57182312011719\n",
      "95 18.496768951416016\n",
      "96 21.415050506591797\n",
      "97 12.474067687988281\n",
      "98 7.89190149307251\n",
      "99 43.35246276855469\n",
      "100 13.613395690917969\n",
      "101 13.787205696105957\n",
      "102 35.660552978515625\n",
      "103 20.072933197021484\n",
      "104 7.598773002624512\n",
      "105 8.022530555725098\n",
      "106 56.609886169433594\n",
      "107 15.092083930969238\n",
      "108 20.879226684570312\n",
      "109 17.208751678466797\n",
      "110 43.02235412597656\n",
      "111 33.8253059387207\n",
      "112 12.171485900878906\n",
      "113 7.698654651641846\n",
      "114 30.446754455566406\n",
      "115 31.222217559814453\n",
      "116 11.431774139404297\n",
      "117 9.808280944824219\n",
      "118 11.77601146697998\n",
      "119 14.29746150970459\n",
      "120 27.997291564941406\n",
      "121 6.886003017425537\n",
      "122 6.996091365814209\n",
      "123 7.7377519607543945\n",
      "124 7.153721332550049\n",
      "125 17.658042907714844\n",
      "126 9.54114818572998\n",
      "127 10.93161392211914\n",
      "128 13.94591999053955\n",
      "129 15.75800609588623\n",
      "130 15.194377899169922\n",
      "131 6.1986165046691895\n",
      "132 4.512242317199707\n",
      "133 4.916548728942871\n",
      "134 5.778925895690918\n",
      "135 42.061641693115234\n",
      "136 3.8156960010528564\n",
      "137 12.856781005859375\n",
      "138 26.86919593811035\n",
      "139 8.284324645996094\n",
      "140 7.509850025177002\n",
      "141 11.70627498626709\n",
      "142 6.860541820526123\n",
      "143 17.31195068359375\n",
      "144 6.002726078033447\n",
      "145 6.673015117645264\n",
      "146 17.03704833984375\n",
      "147 2.9741060733795166\n",
      "148 2.2283575534820557\n",
      "149 12.88019847869873\n",
      "150 21.43107032775879\n",
      "151 3.564323663711548\n",
      "152 6.439619541168213\n",
      "153 32.06920623779297\n",
      "154 4.389238357543945\n",
      "155 3.164966106414795\n",
      "156 3.7244012355804443\n",
      "157 16.148054122924805\n",
      "158 5.63358211517334\n",
      "159 8.939188957214355\n",
      "160 7.104368209838867\n",
      "161 6.096524238586426\n",
      "162 4.14822244644165\n",
      "163 7.186182975769043\n",
      "164 4.056718349456787\n",
      "165 6.014589786529541\n",
      "166 18.183942794799805\n",
      "167 2.6379880905151367\n",
      "168 3.790741443634033\n",
      "169 4.628743648529053\n",
      "170 4.454295635223389\n",
      "171 9.316449165344238\n",
      "172 5.885679721832275\n",
      "173 24.5133113861084\n",
      "174 6.299291610717773\n",
      "175 15.403352737426758\n",
      "176 17.218626022338867\n",
      "177 13.20411491394043\n",
      "178 3.233058214187622\n",
      "179 4.07078742980957\n",
      "180 3.7936713695526123\n",
      "181 18.41637420654297\n",
      "182 3.4613993167877197\n",
      "183 20.306045532226562\n",
      "184 6.249427795410156\n",
      "185 6.340590953826904\n",
      "186 11.593664169311523\n",
      "187 11.736166000366211\n",
      "188 16.886112213134766\n",
      "189 4.0083513259887695\n",
      "190 14.317548751831055\n",
      "191 1.8100550174713135\n",
      "192 8.917787551879883\n",
      "193 16.66189956665039\n",
      "194 5.6158013343811035\n",
      "195 3.459885835647583\n",
      "196 3.081040143966675\n",
      "197 3.800943613052368\n",
      "198 4.424468994140625\n",
      "199 1.477515459060669\n",
      "200 4.54014253616333\n",
      "201 3.4693455696105957\n",
      "202 2.4190807342529297\n",
      "203 3.1471097469329834\n",
      "204 12.791095733642578\n",
      "205 24.56159019470215\n",
      "206 12.511296272277832\n",
      "207 24.062524795532227\n",
      "208 13.722472190856934\n",
      "209 26.402843475341797\n",
      "210 8.457186698913574\n",
      "211 4.492298126220703\n",
      "212 9.142156600952148\n",
      "213 20.648351669311523\n",
      "214 19.29020118713379\n",
      "215 3.9711596965789795\n",
      "216 7.197563171386719\n",
      "217 2.1427218914031982\n",
      "218 0.973905622959137\n",
      "219 51.29229736328125\n",
      "220 33.055904388427734\n",
      "221 7.600881576538086\n",
      "222 6.796086311340332\n",
      "223 20.720136642456055\n",
      "224 39.18765640258789\n",
      "225 22.183528900146484\n",
      "226 12.578408241271973\n",
      "227 1.9149738550186157\n",
      "228 38.2489128112793\n",
      "229 7.296732425689697\n",
      "230 2.593458890914917\n",
      "231 20.032272338867188\n",
      "232 7.561124324798584\n",
      "233 10.922602653503418\n",
      "234 17.782154083251953\n",
      "235 5.295530319213867\n",
      "236 9.858108520507812\n",
      "237 3.4264676570892334\n",
      "238 1.6302618980407715\n",
      "239 2.688807725906372\n",
      "240 17.268041610717773\n",
      "241 28.008939743041992\n",
      "242 7.610570907592773\n",
      "243 2.901399612426758\n",
      "244 17.67568588256836\n",
      "245 21.388580322265625\n",
      "246 30.779949188232422\n",
      "247 1.151410698890686\n",
      "248 3.9969120025634766\n",
      "249 9.227001190185547\n",
      "250 10.104785919189453\n",
      "251 7.7326741218566895\n",
      "252 7.9993577003479\n",
      "253 2.673900842666626\n",
      "254 11.322159767150879\n",
      "255 1.9970571994781494\n",
      "256 1.583513855934143\n",
      "257 4.750421524047852\n",
      "258 3.916712999343872\n",
      "259 1.608710765838623\n",
      "260 6.022869110107422\n",
      "261 3.763601779937744\n",
      "262 3.2739858627319336\n",
      "263 8.438356399536133\n",
      "264 5.419325351715088\n",
      "265 4.8030314445495605\n",
      "266 3.0552031993865967\n",
      "267 4.973011493682861\n",
      "268 2.384945869445801\n",
      "269 5.376274108886719\n",
      "270 5.269714832305908\n",
      "271 2.3907370567321777\n",
      "272 6.092339992523193\n",
      "273 3.168055534362793\n",
      "274 7.306914329528809\n",
      "275 4.089399337768555\n",
      "276 1.1069785356521606\n",
      "277 11.44336223602295\n",
      "278 1.8903567790985107\n",
      "279 1.6906802654266357\n",
      "280 1.2495101690292358\n",
      "281 1.3505791425704956\n",
      "282 4.711686611175537\n",
      "283 26.51616859436035\n",
      "284 1.981361746788025\n",
      "285 11.594254493713379\n",
      "286 30.2421817779541\n",
      "287 30.81849479675293\n",
      "288 4.855262279510498\n",
      "289 2.2142815589904785\n",
      "290 104.2019271850586\n",
      "291 1.4090337753295898\n",
      "292 2.5666685104370117\n",
      "293 9.746011734008789\n",
      "294 5.3307342529296875\n",
      "295 84.7769775390625\n",
      "296 11.770092964172363\n",
      "297 91.27867889404297\n",
      "298 14.829554557800293\n",
      "299 28.54762077331543\n",
      "300 56.73957443237305\n",
      "301 24.336166381835938\n",
      "302 47.28065490722656\n",
      "303 24.508281707763672\n",
      "304 20.107133865356445\n",
      "305 20.421876907348633\n",
      "306 52.8597526550293\n",
      "307 6.441694259643555\n",
      "308 25.213180541992188\n",
      "309 7.861571311950684\n",
      "310 14.403838157653809\n",
      "311 6.369378566741943\n",
      "312 19.36605453491211\n",
      "313 14.80064868927002\n",
      "314 5.819562911987305\n",
      "315 2.360964059829712\n",
      "316 3.51017689704895\n",
      "317 24.662015914916992\n",
      "318 17.409658432006836\n",
      "319 2.8922808170318604\n",
      "320 4.37116813659668\n",
      "321 8.969380378723145\n",
      "322 2.79306960105896\n",
      "323 9.096885681152344\n",
      "324 12.267895698547363\n",
      "325 12.189299583435059\n",
      "326 12.027283668518066\n",
      "327 4.867730617523193\n",
      "328 3.795093536376953\n",
      "329 8.69754695892334\n",
      "330 9.000940322875977\n",
      "331 3.790635824203491\n",
      "332 8.120829582214355\n",
      "333 3.1656551361083984\n",
      "334 3.6147470474243164\n",
      "335 5.416478633880615\n",
      "336 7.797033309936523\n",
      "337 3.828568696975708\n",
      "338 4.085206508636475\n",
      "339 2.023768663406372\n",
      "340 1.0222163200378418\n",
      "341 1.3650505542755127\n",
      "342 14.519877433776855\n",
      "343 17.117874145507812\n",
      "344 4.065049171447754\n",
      "345 3.3573548793792725\n",
      "346 2.032133102416992\n",
      "347 2.9605374336242676\n",
      "348 12.92431640625\n",
      "349 29.947338104248047\n",
      "350 1.1437619924545288\n",
      "351 16.393726348876953\n",
      "352 6.919426441192627\n",
      "353 10.436749458312988\n",
      "354 21.76133918762207\n",
      "355 19.203027725219727\n",
      "356 9.512504577636719\n",
      "357 3.8900704383850098\n",
      "358 1.382959246635437\n",
      "359 4.523416996002197\n",
      "360 26.57965850830078\n",
      "361 6.537223815917969\n",
      "362 5.510955333709717\n",
      "363 1.5954697132110596\n",
      "364 13.483320236206055\n",
      "365 14.766672134399414\n",
      "366 1.1862518787384033\n",
      "367 4.810664176940918\n",
      "368 3.528795003890991\n",
      "369 6.362542629241943\n",
      "370 6.349450588226318\n",
      "371 3.049471855163574\n",
      "372 1.9062113761901855\n",
      "373 2.7614760398864746\n",
      "374 8.120094299316406\n",
      "375 5.386693954467773\n",
      "376 1.2428218126296997\n",
      "377 2.6835598945617676\n",
      "378 3.5565569400787354\n",
      "379 6.837146282196045\n",
      "380 3.1124229431152344\n",
      "381 1.541913390159607\n",
      "382 3.2793145179748535\n",
      "383 2.990262746810913\n",
      "384 4.552473068237305\n",
      "385 1.3702328205108643\n",
      "386 0.8100935220718384\n",
      "387 3.0167269706726074\n",
      "388 1.3734067678451538\n",
      "389 2.61497163772583\n",
      "390 1.4416111707687378\n",
      "391 1.8115583658218384\n",
      "392 1.1698583364486694\n",
      "393 1.6113529205322266\n",
      "394 0.7925043106079102\n",
      "395 0.9622522592544556\n",
      "396 0.9118265509605408\n",
      "397 3.0173511505126953\n",
      "398 1.4241644144058228\n",
      "399 0.8014470338821411\n",
      "400 1.5531702041625977\n",
      "401 1.0689340829849243\n",
      "402 1.4251837730407715\n",
      "403 2.1901519298553467\n",
      "404 1.7800687551498413\n",
      "405 0.7080175876617432\n",
      "406 0.6719964742660522\n",
      "407 1.9813945293426514\n",
      "408 0.6538594365119934\n",
      "409 1.305738091468811\n",
      "410 0.5664792656898499\n",
      "411 0.6408385634422302\n",
      "412 1.272457480430603\n",
      "413 1.0774176120758057\n",
      "414 0.5674421191215515\n",
      "415 0.4528314769268036\n",
      "416 1.2130515575408936\n",
      "417 0.6124825477600098\n",
      "418 1.076338529586792\n",
      "419 0.6975710988044739\n",
      "420 0.2750011384487152\n",
      "421 0.7920515537261963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422 0.6274687647819519\n",
      "423 0.48405390977859497\n",
      "424 0.6427448987960815\n",
      "425 1.2076305150985718\n",
      "426 0.3755315840244293\n",
      "427 0.34131568670272827\n",
      "428 1.3832424879074097\n",
      "429 1.135175347328186\n",
      "430 0.8895307183265686\n",
      "431 0.18624252080917358\n",
      "432 0.17079602181911469\n",
      "433 0.7771769165992737\n",
      "434 1.5193232297897339\n",
      "435 0.900846540927887\n",
      "436 0.2907845675945282\n",
      "437 1.475878357887268\n",
      "438 0.9613882303237915\n",
      "439 0.21398164331912994\n",
      "440 1.7474861145019531\n",
      "441 0.9462482929229736\n",
      "442 0.12378840893507004\n",
      "443 2.0909337997436523\n",
      "444 1.2660235166549683\n",
      "445 0.6944770812988281\n",
      "446 1.34846830368042\n",
      "447 2.4604618549346924\n",
      "448 0.5241389870643616\n",
      "449 1.114463448524475\n",
      "450 2.7613863945007324\n",
      "451 2.2705211639404297\n",
      "452 0.7001661062240601\n",
      "453 0.6466460227966309\n",
      "454 1.1816885471343994\n",
      "455 1.2818185091018677\n",
      "456 0.6187728643417358\n",
      "457 1.1254522800445557\n",
      "458 1.4914904832839966\n",
      "459 0.792904794216156\n",
      "460 0.584405243396759\n",
      "461 0.8607895374298096\n",
      "462 1.1965233087539673\n",
      "463 0.7310009002685547\n",
      "464 0.42578762769699097\n",
      "465 0.534474790096283\n",
      "466 0.46397027373313904\n",
      "467 0.7929109930992126\n",
      "468 0.9968922138214111\n",
      "469 0.7086250185966492\n",
      "470 0.5414153933525085\n",
      "471 0.22439970076084137\n",
      "472 0.7464924454689026\n",
      "473 0.31941476464271545\n",
      "474 2.3825581073760986\n",
      "475 0.9320685267448425\n",
      "476 0.5000717639923096\n",
      "477 1.710172176361084\n",
      "478 1.4735584259033203\n",
      "479 1.3701335191726685\n",
      "480 0.2901424467563629\n",
      "481 0.12278898805379868\n",
      "482 1.5399855375289917\n",
      "483 0.6706554889678955\n",
      "484 0.14380478858947754\n",
      "485 0.8514886498451233\n",
      "486 1.18820321559906\n",
      "487 0.9733659625053406\n",
      "488 0.33976757526397705\n",
      "489 4.62939977645874\n",
      "490 0.8646062016487122\n",
      "491 0.3411022424697876\n",
      "492 0.5034810304641724\n",
      "493 0.8189080953598022\n",
      "494 14.784317970275879\n",
      "495 1.1912486553192139\n",
      "496 4.94266414642334\n",
      "497 0.9776403307914734\n",
      "498 6.181485652923584\n",
      "499 0.49260395765304565\n"
     ]
    }
   ],
   "source": [
    "for t in range(500):\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
